{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ZlyngAPxgmEL"
   },
   "source": [
    "# Addiscore - Une application au service de la santé publique\n",
    "- **Projet 3 du parcours « Data Scientist » d’OpenClassrooms**\n",
    "- **Mark Creasey**\n",
    "\n",
    "## Étape 1 : Nettoyage des données\n",
    "\n",
    "L'agence \"Santé publique France\" a **lancé un appel à projets pour trouver des idées innovantes d’applications en lien avec l'alimentation.** \n",
    "\n",
    "<a href=\"https://user.oc-static.com/upload/2019/02/23/15509423491012_logo.png\" class=\"oc-imageLink oc-imageLink--disabled\"><img src=\"https://user.oc-static.com/upload/2019/02/23/15509423491012_logo.png\" alt=\"L'agence Santé publique France\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION: D'abord, spécifier les valeurs des variables dans le code ci-dessous**:\n",
    "- **ENV** = 'local', 'colab' ou 'kaggle' (environnement de travail)\n",
    "- **USE_SAMPLE** = True (echantillon *'data_sample.csv'*) ou False (base entière)\n",
    "- **SAVE_IMAGES** = True (enregistre graphiques) ou False\n",
    "\n",
    "Avec un échantillon de 100,000 registres, ce notebook doit prendre moins de 5 minutes pour éxecuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV='local'\n",
    "USE_SAMPLE=True\n",
    "SAVE_IMAGES=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlgjPvengIo6"
   },
   "source": [
    "---\n",
    "\n",
    "# Table de matières<a name=\"toc\"></a>\n",
    "\n",
    "- [0. Configuration de l'environnement de travail](#0.-Configuration-de-l'environnement-de-travail)\n",
    "- [1. Idée d'application](#1.-Idée-d'application)\n",
    "- [2. Importation des données <a name=\"importation\"></a>](#2.-Importation-des-données-<a-name=\"importation\"></a>)\n",
    "- [3. Elimination de colonnes non-pertinentes et lignes dupliquées](#3.-Elimination-de-colonnes-non-pertinentes-et-lignes-dupliquées)\n",
    "- [4. Étude des valeurs manquantes<a name=\"valeurs-manquants\"></a>](#4.-Étude-des-valeurs-manquantes<a-name=\"valeurs-manquants\"></a>)\n",
    "- [5. Nettoyage des valeurs aberrantes<a name=\"valeurs-aberrants\"></a>](#5.-Nettoyage-des-valeurs-aberrantes<a-name=\"valeurs-aberrants\"></a>)\n",
    "- [6. Etude des valeurs atypiques](#6.-Etude-des-valeurs-atypiques)\n",
    "- [7. Imputation de valeurs manquantes](#7.-Imputation-de-valeurs-manquantes)\n",
    "- [8. Élimination des colonnes redondantes<a name=\"colonnes-redondantes\"></a>](#8.-Élimination-des-colonnes-redondantes<a-name=\"colonnes-redondantes\"></a>)\n",
    "- [9. Enregistrement du dataframe nettoyé<a name=\"enregistrement\"></a>](#9.-Enregistrement-du-dataframe-nettoyé<a-name=\"enregistrement\"></a>)\n",
    "- [10. Conversion des données supplémentaires des additives (du site Open Food Facts)](#10.-Conversion-des-données-supplémentaires-des-additives-(du-site-Open-Food-Facts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ch3ZdbWXT4D"
   },
   "source": [
    "# 0. Configuration de l'environnement de travail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slIeYGbDd30j"
   },
   "source": [
    "## 0.1 Definition de l'environnement\n",
    "Variable **ENV** spécifié au début du notebook: \n",
    "- `local`  : Développement local (avec échantillon de 20 Mo de données)\n",
    "- `colab`  : Google Colab\n",
    "- `kaggle` : Kaggle Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAKrDtU0d5uB"
   },
   "outputs": [],
   "source": [
    "if ENV=='local':\n",
    "    # local development\n",
    "    DATA_FOLDER = 'data/raw'\n",
    "    OUT_FOLDER = 'data/out'\n",
    "    IMAGE_FOLDER = 'images/nettoyage'\n",
    "\n",
    "if ENV == 'colab':\n",
    "    # Colaboratory - uncomment les 2 lignes suivant pour connecter à votre drive\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    DATA_FOLDER = '/content/drive/MyDrive/data'\n",
    "    OUT_FOLDER = '/content/drive/MyDrive/data'\n",
    "    IMAGE_FOLDER = '/content/drive/MyDrive/images/nettoyage'\n",
    "\n",
    "if ENV == 'kaggle':\n",
    "    DATA_FOLDER = '/kaggle/input/openfoodfacts'\n",
    "    OUT_FOLDER = '/kaggle/working/'\n",
    "    IMAGE_FOLDER = '/kaggle/working/images/nettoyage'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsSTcRomY5yC"
   },
   "source": [
    "## 0.2 Fichiers de données\n",
    "\n",
    "Variable **USE_SAMPLE** (True ou False) est spécifié au début du notebook: \n",
    "\n",
    "1. Les données en format CSV (>4.3Gb) sont à télecharger du site <https://world.openfoodfacts.org/data> ou directement de ce lien: [en.openfoodfacts.org.products.csv](https://static.openfoodfacts.org/data/en.openfoodfacts.org.products.csv)\n",
    "2. Placer le fichier CSV dans le **DATA_FOLDER** défini ci-dessous (*ou sous linux/macOS, une version compacté avec le nom 'en.openfoodfacts.org.products.zip' qui sera decompacté avec la commande `!unzip`*)\n",
    "3. Alternativement, placer un échantillon des données avec le nom **'data_sample.csv'** dans le **DATA_FOLDER** défini ci-dessous, et definir le variable **`USE_SAMPLE = True`** au début de ce notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "BXz2hkEdgmEU"
   },
   "source": [
    "### Noms des fichiers de données (identique pour nettoyage et l'analyse exploratoire)\n",
    "\n",
    "- Le grand fichier des données de OpenFoodFacts doit être placé dans `DATA_FOLDER` au préalable \n",
    "- Tous les autres fichiers de données sont téléchargés ou crées pendant le nettoyage, puis enregistrés dans `OUT_FOLDER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEYIJPSYgmEU",
    "outputId": "dbd2f992-a7d8-4ec6-b87d-9a4e5407fd14"
   },
   "outputs": [],
   "source": [
    "# Données (DATA_FOLDER)\n",
    "ZIPPED_DATA_FILENAME=f'en.openfoodfacts.org.products.zip'\n",
    "RAW_DATA_FILENAME='en.openfoodfacts.org.products.csv'\n",
    "SAMPLE_DATA_FILENAME='data_sample.csv' # 100,000 registres\n",
    "\n",
    "# Données nettoyés (OUT_FOLDER)\n",
    "CLEAN_DATA_FILENAME='cleaned_data_openfoodfacts.csv'\n",
    "CLEAN_DATA_SAMPLE='cleaned_data_sample.csv' # 100,000 registres\n",
    "\n",
    "# dictionnaires de données (OUT_FOLDER)\n",
    "RAW_DATA_DICT='raw_data_dict.csv'\n",
    "CLEAN_DATA_DICT='cleaned_data_dict.csv'\n",
    "\n",
    "# Données supplémentaires (OUT_FOLDER)\n",
    "ADDITIVES_DETAIL='additives_detail.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beG3LBOdjalJ"
   },
   "source": [
    "## 0.3 Requirements: Bibliothèques utilisées dans ce notebook\n",
    "\n",
    "Ce notebook marche a été testé en developpement local, sur Google Colab et Kaggle.\n",
    "\n",
    "La liste des bibliothèques utilisées sont enregistrés dans un fichier `requirements.txt`\n",
    "\n",
    "Il y a 3 façons de les installer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3.1 Fichier requirements.txt\n",
    "\n",
    "pour installer, `%pip install -r requirements.txt`\n",
    "\n",
    "```txt\n",
    "python>=3.7.0,<3.10\n",
    "numpy>=1.19.5,<1.22\n",
    "pandas>=1.1.5,<1.4 \n",
    "matplotlib>=3.2.2,<3.6\n",
    "seaborn==0.11.2\n",
    "scikit-learn>=1.0.1,<1.1\n",
    "scipy>=1.4.1,<=1.8\n",
    "statsmodels==0.12\n",
    "missingno>=0.4.2,<0.6\n",
    "requests>=2.23.0,<2.27\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3.2 Installation des bibliothèques\n",
    "Choisir entre les 3 options:\n",
    "- %pip install <package_manquante>\n",
    "- %pip install -requirements.txt (versions spécifiques)\n",
    "- install_libraries fonction (pas besoin de decommentarise les lignes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOOttIYZU1q0"
   },
   "outputs": [],
   "source": [
    "# Decommentarise la ligne suivant si vous ne voulez pas changer vos versions existants\n",
    "# %pip install numpy pandas matplotlib seaborn scipy scikit-learn statsmodels missingno requests\n",
    "# ou \n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_libraries(required={}) -> None:\n",
    "    \"\"\"\n",
    "    Installation des bibliothèques manquantes\n",
    "    https://stackoverflow.com/questions/44210656/\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import subprocess\n",
    "    import pkg_resources\n",
    "    installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "    missing = set(required) - set(installed)\n",
    "    if missing:\n",
    "        print(f'missing libraries: {missing}')\n",
    "        python = sys.executable\n",
    "        subprocess.check_call([python, '-m', 'pip', 'install', *missing],\n",
    "                              stdout=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "install_libraries({'numpy','pandas','matplotlib','seaborn','scipy','scikit-learn','statsmodels','missingno','requests'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5trk26YWr8O"
   },
   "source": [
    "## 0.4 Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "W9OMq8ZagmES"
   },
   "source": [
    "### 0.4.1 Import des bibliothèques utilisées par ce notebook\n",
    "- il faut redémarrer le kernel si vous venez d'installer les bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geF-PEmZgmES"
   },
   "outputs": [],
   "source": [
    "# suppress future warnings de pandas 1.3.0  \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import scipy.stats as stats\n",
    "import missingno as msno\n",
    "import requests\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHls8mr4gmET"
   },
   "source": [
    "### 0.4.2 Liste des versions des bibliothèques utilisées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvuaiN3CgmET",
    "outputId": "6266b07c-cfb3-4a3a-ca69-9a63f94dc710"
   },
   "outputs": [],
   "source": [
    "!python --version\n",
    "print('versions des bibliothèques utilisées:')\n",
    "print('; '.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05kEHjV5gmET"
   },
   "source": [
    "Copie des versions :\n",
    "\n",
    "        Python 3.9.7\n",
    "        versions des bibliothèques utilisées:\n",
    "        numpy==1.21.2; pandas==1.3.4; seaborn==0.11.2; requests==2.26.0; json==2.0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "YVFI7uibgmET"
   },
   "source": [
    "### 0.4.3 Configuration défauts d'affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq-qnBOngmET"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)  # pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_rows', 10)  # pour afficher max 10 lignes\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"white\", context=\"notebook\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.set_palette(\"tab20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzhG7OZElHcY"
   },
   "source": [
    "## 0.5 Fonctions utilitaires (make_dirs, savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def os_make_dir(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def os_path_join(folder, file):\n",
    "    \"\"\"remplacement pour `os.path.join(folder, file)` sur windows\"\"\"\n",
    "    return f'{folder}/{file}'\n",
    "\n",
    "if ENV !='kaggle': \n",
    "    os_make_dir(DATA_FOLDER)\n",
    "    os_make_dir(OUT_FOLDER)\n",
    "\n",
    "os_make_dir(IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour enregistrer les graphiques, define **SAVE_IMAGES = True** au debut de ce notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa2QvZi2gmEU"
   },
   "outputs": [],
   "source": [
    "def to_png(fig_name):\n",
    "    \"\"\"\n",
    "    enregistre l'image dans un fichier\n",
    "    il faut appélé avant plt.show() pour pouvoir ajuster la taille de l'image\n",
    "    avec bbox_inches=tight pour etre sur d'inclure le titre /legende entier.\n",
    "    \"\"\"\n",
    "    if SAVE_IMAGES:\n",
    "        \"\"\"Enregistre l'image\"\"\"\n",
    "        plt.gcf().savefig(os_path_join(IMAGE_FOLDER,f'{fig_name}.png'), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "YsBh47Q6gmEM"
   },
   "source": [
    "---\n",
    "# 1. Idée d'application\n",
    "- Pourquoi cette application\n",
    "- Fonctionnement de l'application (proposé) :\n",
    "- Étapes de traitement de données pour l'application\n",
    "- Procès itératif de traitement de données\n",
    "\n",
    "## 1.1 Une 'addiscore' pour éviter les additifs 'mauvais' pour la santé<a name=\"idee-application\"></a>\n",
    "\n",
    "> *Consuming small amounts of additives may be safe, but the health risks add up if you rely heavily on processed foods.*\n",
    "> *A diet rich in processed foods is linked to chronic diseases such as obesity, high blood pressure, heart disease and cancer.*\n",
    "\n",
    "> _(Source : https://ec.europa.eu/food/safety/food-improvement-agents/additives_en)_\n",
    "\n",
    "\n",
    "Sur le site d'OpenFoodFacts, on note une quantité significative de produits qui contient des additifs qui peuvent pose un risque à notre santé :\n",
    "- https://world.openfoodfacts.org/additives\n",
    "\n",
    "\n",
    "Beaucoup des presque 600 additifs sont naturels, pas nocifs pour la santé, et très util : acide citrique, les pectines, agar, carbonate de soda, oxygen, par exemple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ihrSQ2G6gmEN"
   },
   "source": [
    "## 1.2 Pourquoi cette application\n",
    "\n",
    "### Trop complex et chronophage\n",
    "\n",
    "Les gens n'ont pas le temps pour lire tous les ingredients,\n",
    "\n",
    "### Simplifier le choix\n",
    "\n",
    "Les applications ne permettent pas de sélectionner entre les 650 additifs, lesquels sont 'acceptables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "3onFOqGlgmEN"
   },
   "source": [
    "\n",
    "## 1.2 Fonctionnement de l'application (proposé) :\n",
    "\n",
    "1. identifier si un produit contient un ou plus d'additifs à risque de sur-exposure\n",
    "  - A_none : aucune additif\n",
    "  - B_low  : contient additifs sans risque\n",
    "  - C_mod  : contient additifs à risque modéré de sur-exposure\n",
    "  - D_high : contient additifs à haut risque de sur-exposure \n",
    "2. calculer un ADDISCORE, qui \n",
    "  - combine le nombre d'additifs dans chaque catégorie de risque \n",
    "   avec des coefficients (poids) pour chaque groupe de risque  \n",
    "3. proposer des produits le plus similaires (catégorie) qui\n",
    "  - ont le meilleur ADDISCORE (plus bas)\n",
    "  - ont le meilleur nutriscore (plus bas)\n",
    "  - ne contient pas d'huile de palme (généralement listé comme ingredient, parfois comme additif)\n",
    "4. s'il n'y a pas des produits similaires (avec liste d'ingrédients) :\n",
    "  - proposer des produits de la même catégorie, mais plus proche en valeurs nutritionnelles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "2eXdJbkvgmEN"
   },
   "source": [
    "## 1.3 Étapes de traitement de données pour l'application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "mMqFEezOgmEO"
   },
   "source": [
    "### Pour identifier si un produit contient des additifs à risque de sur-exposure :\n",
    "- verifier que les ingredients sont présents (`state == en:ingredients-completed` ou `additifs_n >=0`)\n",
    "- obtenir une liste d'additifs à risque (`https://world.openfoodfacts.org/data/taxonomies/additives.json`)\n",
    "- identifier les produits qui contiennent des additifs à risque (`additives_tags` contient 1 ou plus additif à risque)\n",
    "- conter le nombre d'additifs dans chaque niveau de risque: `risk_high_n`, `risk_mod_n`, `risk_low_n`\n",
    "- marquer les produits en quatre catégories d'additifs : `high`, `moderate`, `low`, `none` (ou N/A - inconnu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "9KET7JUggmEP"
   },
   "source": [
    "### Pour proposer les produits similaires\n",
    "- sélectionner une colonne de catégories pour associer le produit (à définir)\n",
    "- avoir accès au nutriscore, nutrigrade, groupe nova\n",
    "- avoir la liste d'additifs, pour choisir ce qui à moins d'additifs\n",
    "\n",
    "### Pour proposer les produits avec valeurs nutritionnels similaires\n",
    "- avoir les colonnes utilisées pour calculer le nutriscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "GqOpsTxOgmEQ"
   },
   "source": [
    "## 1.4 Procès itératif de traitement de données\n",
    "\n",
    "- Iteration 1 : Un premier nettoyage et analyse exploratoire avec les données filtrés (aucune donnée imputée)\n",
    "- Itération 2 : Imputation/prédiction des nutriscores / nutrigrades manquantes (à faire)\n",
    "- Itération 3 : Imputation/prédiction des groupes 'nova' manquants (à faire)\n",
    "- Itération 4 : Imputation/prédiction des additifs potentiels dans des produits sans ingredients, basé sur product name, categories, pays d'origine (à faire)\n",
    "\n",
    "Cette nettoyage et exploration concentre sur les iterations 1 et 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "1Bb75dZhgmEQ"
   },
   "source": [
    "---\n",
    "\n",
    "# 2. Importation des données <a name=\"importation\"></a>\n",
    "\n",
    "- Import des données\n",
    "- Vérification et correction du typage des colonnes\n",
    "- Pipeline pour corriger les types après import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "f8INDTkpgmEU"
   },
   "source": [
    "## 2.2 Configuration de l'importation des données\n",
    "\n",
    "### 2.2.1 Choix de fichier à analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXRscN-_gmEU",
    "outputId": "f026493b-60d7-4f72-cea4-03a324fe4df8"
   },
   "outputs": [],
   "source": [
    "DATA_FILENAME = SAMPLE_DATA_FILENAME if USE_SAMPLE==True else RAW_DATA_FILENAME\n",
    "RAW_DATA = os_path_join(DATA_FOLDER, DATA_FILENAME)\n",
    "DATA_ZIPPED = os_path_join(DATA_FOLDER,ZIPPED_DATA_FILENAME)\n",
    "print(f'data file: {RAW_DATA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1QVXafsgmEV",
    "outputId": "37909bca-4569-4ced-f945-f81b07edf6c9"
   },
   "outputs": [],
   "source": [
    "def unzip_data_si_besoin(env=ENV):\n",
    "    \"\"\"procedure pour unzip sur Google Drive via Google Colab\"\"\"\n",
    "    if os.path.exists(RAW_DATA):\n",
    "        print(f'data CSV file exists ({RAW_DATA})')\n",
    "    else:\n",
    "        print(f'data CSV file does not exist ({RAW_DATA})')\n",
    "        if env=='colab' and os.path.exists(DATA_ZIPPED):\n",
    "            # uncomment les 3 lignes suivants\n",
    "            print (f'unzipping {DATA_ZIPPED}')\n",
    "            !unzip {DATA_ZIPPED} -d {DATA_FOLDER}\n",
    "            print (f'{DATA_ZIPPED} has been unzipped')\n",
    "            if os.path.exists(RAW_DATA):\n",
    "                print(f'data CSV file now exists ({RAW_DATA})')\n",
    "        else:\n",
    "            print(f'zipped data does not exist ({DATA_ZIPPED})')\n",
    "\n",
    "unzip_data_si_besoin(ENV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xlmhCpTHgmEV"
   },
   "source": [
    "### 2.2.2 Information sur le fichier (taille, type, nb. registres, champs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qnmwBoi9gmEV",
    "outputId": "03e8cd0f-b492-4e34-839c-36074a3bb637"
   },
   "outputs": [],
   "source": [
    "def get_size_str(octets):\n",
    "    gb = round(octets / 2 ** 30, 2)\n",
    "    mb = round(octets / 2 ** 20, 2)\n",
    "    kb = round(octets / 2 ** 10, 2)\n",
    "    if gb > 1:\n",
    "        ret = f'{gb} Go'\n",
    "    elif mb > 1:\n",
    "        ret = f'{mb} Mo'\n",
    "    elif kb > 1:\n",
    "        ret = f'{kb} ko'\n",
    "    else:\n",
    "        ret = f'{octets} octets'\n",
    "    return ret\n",
    "\n",
    "def get_filesize(file_path=RAW_DATA):\n",
    "    \"\"\"Taille du fichier\"\"\"\n",
    "    octets = os.stat(file_path).st_size\n",
    "    return get_size_str(octets)\n",
    "\n",
    "get_filesize(RAW_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "0_yXdh1SgmEV"
   },
   "source": [
    "#### Combien de lignes de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87gKJoz-gmEV",
    "outputId": "5fe78539-1642-4fd9-df2d-1765699191d6"
   },
   "outputs": [],
   "source": [
    "def count_rows(file_path=RAW_DATA):\n",
    "    fp = open(file_path, encoding='UTF-8')\n",
    "    i = -1\n",
    "    # return sum(1 for row in fp)\n",
    "    for i, row in enumerate(fp): pass\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "lignes = count_rows(RAW_DATA)\n",
    "print(f'nb registres (incl en-têtes) : {lignes}')\n",
    "# returns 2,042,130 after 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "fEhe1V5GgmEW"
   },
   "source": [
    "#### Quelle est le format des données ?\n",
    "- lecture de premier 2 lignes pour determiner le format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtzPEVgsgmEW",
    "outputId": "85a56d96-0e7a-411c-c882-3aa20f2dec49"
   },
   "outputs": [],
   "source": [
    "def read_file_rows(file_path=RAW_DATA, nb_rows=1):\n",
    "    fp = open(file_path, encoding='UTF-8')\n",
    "    for i in range(nb_rows + 1):\n",
    "        row = fp.readline()\n",
    "        print(f'Line {i} :\\n{row}')\n",
    "\n",
    "\n",
    "read_file_rows(RAW_DATA, nb_rows=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Ntw0I4DRgmEW"
   },
   "source": [
    "#### Format des données :\n",
    "\n",
    "- La premiere ligne contient les en-têtes (column names)\n",
    "- Les données semblent séparées par tab (`\\t`)\n",
    "- Les accents {à, é, è ...} sont reconnus si on passe le paramètre `encoding = UTF-8`\n",
    "\n",
    "### 2.2.3 Pertinence des colonnes :\n",
    "\n",
    "Il semble que les colonnes des urls et des 'states' vont prendre beaucoup d'espace, mais sont probablement inutiles pour l'analyse exploratoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ivS20V-agmEW"
   },
   "source": [
    "### 2.2.4 Import un échantillon pour tester l'identification de data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "ptnB2Ze4gmEW",
    "outputId": "afe0d0d2-13a9-4524-cceb-a3d8900b7f74"
   },
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(RAW_DATA, sep='\\t',header=0, encoding='UTF-8', nrows=1000)\n",
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WjqYm5ngmEW",
    "outputId": "6af7a46f-e43e-4969-8c8b-ad489487f65b"
   },
   "outputs": [],
   "source": [
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cYwat8xRgmEX"
   },
   "source": [
    "### 2.2.5 Conclusion\n",
    "- Le fichier à analyser est très grand (4.3 Go)\n",
    "- Il contient plus de 2 millions de registres\n",
    "- Chaque row est composé de presque 190 colonnes en format UTF-8, séparés par tabulations\n",
    "- Beaucoup de colonnes textuelles\n",
    "- L'import d'un échantillon semble marcher bien\n",
    "\n",
    "On va essayer d'importer le fichier entier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "RTANoMlmgmEX"
   },
   "source": [
    "## 2.3 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqM13ymKgmEX"
   },
   "outputs": [],
   "source": [
    "# data_df = pd.read_csv(RAW_DATA, sep='\\t', header=0, encoding='utf-8', low_memory=True) # Crashes\n",
    "# data_df = pd.read_csv(RAW_DATA, sep='\\t', header=0, encoding='utf-8', low_memory=False) # Crashes sur RAM 4Go Google Colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhCzFsNRgmEX"
   },
   "source": [
    "Les premières tentatives d'importation de la base de données complète ont produit des erreurs d'import :\n",
    "```\n",
    "DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
    "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "```\n",
    "\n",
    "Peut-être en réduisant la nombre de colonnes à importer on peut éviter ce message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cMDGtNiggmEX"
   },
   "source": [
    "### 2.3.1 Choix manuel des colonnes à importer\n",
    "\n",
    "1000 registres prend 1.4Mo.\n",
    "\n",
    "La base contienne 2000 fois de registres, soit 4 Go de memoire.\n",
    "\n",
    "- Est-ce qu'il faut importer des gros colonnes dont on n'a pas besoin\n",
    "- si la base est trop grande, élimine ces colonnes\n",
    "\n",
    "#### Quel sont les colonnes les plus volumineux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "pXyYGZmFgmEY",
    "outputId": "41d46f68-99a8-4171-8858-48a267f89268"
   },
   "outputs": [],
   "source": [
    "df_sample.memory_usage(deep=True).to_frame('freq').sort_values(by='freq',ascending =False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "w6o_oM3lgmEY"
   },
   "source": [
    "#### Ne pas importer les colonnes des urls des images\n",
    "- les colonnes des urls pour les images des produits sont très volumineuses\n",
    "- ils ne seront pas utils pour l'analyse actuelle\n",
    "- on peut utiliser deep learning (analyse d'images) plus tard pour inférer la catégorie, les ingredients, la nutrition...\n",
    "\n",
    "On garde les autres colonnes volumineuses\n",
    "- les states (possibilité de filtrer les données validées et données manquantes)\n",
    "- les ingredients (possibilité d'associer aux additifs),\n",
    "- les categories (peut être utile pour prédire nutriscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bm9NukTdgmEY",
    "outputId": "5a9583d2-688c-48c8-e0f6-8e87525ab3f1"
   },
   "outputs": [],
   "source": [
    "url_cols=df_sample.columns[df_sample.columns.str.endswith('_url')].tolist()\n",
    "print(url_cols)\n",
    "\n",
    "colonnes_a_importer = df_sample.columns[~df_sample.columns.str.endswith('_url')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTStbLZ2gmEY"
   },
   "outputs": [],
   "source": [
    "# data_df = pd.read_csv(RAW_DATA, sep='\\t', header=0, encoding='utf-8',\n",
    "#                          usecols=colonnes_a_importer,\n",
    "#                          low_memory=True\n",
    "#                          ) # Warning: dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Ls-iNIekgmEY"
   },
   "source": [
    "Même après enlever les colonnes _url, le warning persiste, donc il faut specifier le dtype\n",
    "\n",
    "Une [réponse sur stackoverflow](https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options) explique pourquoi il faut spécifier le dtype (les types des données) pendant import, et ajout des convertisseurs si besoin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "7JtkwGqkgmEY"
   },
   "source": [
    "### 2.3.2 Créer un dictionnaire de types pour éviter erreurs d'inférence de type et accélérer l'import\n",
    "- crée le dictionnaire à partir d'un échantillon de données\n",
    "- modifié le dictionnaire avec les descriptions fournies par\n",
    "    - <https://world.openfoodfacts.org/data/data-fields.txt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWOyjyn4gmEY",
    "outputId": "a02fb220-e59d-4c2f-d046-b1dbba1377a2"
   },
   "outputs": [],
   "source": [
    "dict_dtypes = dict(df_sample.dtypes.astype(str))\n",
    "del df_sample\n",
    "dict_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wXeA0Ag-gmEY"
   },
   "source": [
    "on note:\n",
    "- les champs qui terminent avec _n doivent être 'integer', pas float\n",
    "- le champ 'nova_group' est traité com float, mais c'est un entier\n",
    "- les champs qui terminent par `_t` sont de type unix timestamp ('epoch time') et doivent être converti manuellement,\n",
    "  soit pendant l'import ou après import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhm9cqVogmEZ"
   },
   "outputs": [],
   "source": [
    "def correct_dtypes(dtypes:dict)->dict:\n",
    "    ret= dtypes.copy()\n",
    "    for col in dtypes:\n",
    "        if col.endswith(('_n','nova_group')):\n",
    "            ret[col] = 'uint64'  \n",
    "        elif col.endswith(('_datetime', '_t')):\n",
    "            # on va convertir les dates et epoch time en datetime pendant import\n",
    "            # ret.pop(col, None)\n",
    "            continue\n",
    "        else:\n",
    "           continue\n",
    "    return ret\n",
    "\n",
    "correct_dict_dtypes = correct_dtypes(dict_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "BpcPAvRVgmEZ"
   },
   "source": [
    "### 2.3.3 Convertisseurs des dates pendant l'import\n",
    "Utilise les descriptions fournies par\n",
    "- https://world.openfoodfacts.org/data/data-fields.txt\n",
    "- l'échantillon de df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vph1KsOCgmEZ"
   },
   "outputs": [],
   "source": [
    "# Si besoin de conversion de dates, independent du timezone\n",
    "from dateutil import parser\n",
    "convert_from_iso8601 = lambda x: parser.parse(x, ignoretz=True) # utilise utc\n",
    "converters_datetime = {col: convert_from_iso8601 for col in ['created_datetime', 'last_modified_datetime']}\n",
    "\n",
    "# Besoin de conversion de epoch times\n",
    "from datetime import datetime\n",
    "convert_from_epoch_time = lambda x: datetime.utcfromtimestamp(int(x))\n",
    "converters_epoch_time = {col: convert_from_epoch_time for col in ['created_t', 'last_modified_t']}\n",
    "\n",
    "# convertisseurs = dict(**converters_epoch_time,**converters_datetime, **converter_nova_group)\n",
    "convertisseurs = dict(**converters_epoch_time, **converters_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQxx2Fo8U8Rw"
   },
   "outputs": [],
   "source": [
    "colonnes_a_importer=['code', 'creator', 'created_datetime', 'last_modified_datetime', 'product_name', 'quantity', 'brands','brands_tags', 'categories_en', 'labels_en', 'countries_en', 'ingredients_text', 'serving_size', 'serving_quantity', 'additives_n', 'additives_tags', 'additives_en', 'ingredients_from_palm_oil_n', 'ingredients_from_palm_oil_tags', 'ingredients_that_may_be_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_tags', 'nutriscore_score', 'nutriscore_grade', 'nova_group', 'pnns_groups_1', 'pnns_groups_2', 'states_en', 'ecoscore_score_fr', 'ecoscore_grade_fr', 'main_category', 'main_category_en', 'energy_100g', 'fat_100g', 'saturated-fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'proteins_100g', 'sodium_100g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "yFc_3k9ogmEZ"
   },
   "source": [
    "## 2.4 Import des données (colonnes sélectionnées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-hBWXVQgmEZ",
    "outputId": "a65d3e1d-5005-475c-c397-561568efd0b7"
   },
   "outputs": [],
   "source": [
    "def read_raw_data(file=RAW_DATA, colonnes=None, dict_dtypes=None):\n",
    "    # return pd.read_csv(file, sep='\\t', header='infer', encoding='utf-8', low_memory=True, nrows=200000)\n",
    "    # return pd.read_csv(file, sep='\\t', header=0, encoding='utf-8', low_memory=False) # Crashes\n",
    "    if colonnes is None:\n",
    "        return pd.read_csv(file, sep='\\t', header=0, encoding='utf-8', low_memory=True) # Warning: dtypes\n",
    "    elif dict_dtypes is None:\n",
    "        return pd.read_csv(file, sep='\\t', header=0, encoding='utf-8', low_memory=True, usecols=colonnes) # Warning: dtypes\n",
    "    else:\n",
    "        return pd.read_csv(file, sep='\\t', header=0, encoding='utf-8', low_memory=True, usecols=colonnes_a_importer, dtype=dict_dtypes)\n",
    "\n",
    "data_df=read_raw_data()\n",
    "data_df_shape=data_df.shape\n",
    "\n",
    "data_df.info(verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IZXmMEyK-BU",
    "outputId": "2cf614b6-fec4-4c7b-b9e5-d4563c31f288"
   },
   "outputs": [],
   "source": [
    "mem_usage=data_df.memory_usage(index=True,deep=True).sort_values(ascending=False)\n",
    "print(f'taille en memoire = {get_size_str(mem_usage.sum())}')\n",
    "mem_usage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exQfjo-U1xNj"
   },
   "source": [
    "Quand on importe la base entière, la taille en memoire est trop grand (>10 Go):\n",
    "- on ne peut pas faire des analyses comme la visualisation des données manquantes\n",
    "- Les colonnes d'additifs ont trop de données manquantes - il faut comprendre pourquoi.  \n",
    "\n",
    "Pour analyser les données manquantes, il faut:\n",
    "- option 1 - prendre un échantillon\n",
    "- option 2 - supprimer les colonnes non-pertinentes à l'analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j25ayzPOzf39"
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "# msno.matrix(data_df) # crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SECniD2i0o3F"
   },
   "source": [
    "### 2.4.1 Option 1 pour réduire la taille en memoire - Prendre un échantillon\n",
    "Des echantillons étaient utilisés en mode local pour accélerer la developpement de routines de nettoyage\n",
    "Ce notebook est maintenant capable de nettoyer la base entier, avec un RAM de 12Go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HQs45Xa01eQ"
   },
   "outputs": [],
   "source": [
    "def sample_si_besoin(df, max_gigabytes=4):\n",
    "    memory_size=df.memory_usage(index=True,deep=True).sum()\n",
    "    max_bytes = max_gigabytes*1024*1024*1024\n",
    "    nb_registres=df.shape[0] \n",
    "    bytes_per_registre=round(memory_size/nb_registres)\n",
    "    print(f'taille en memoire = {get_size_str(memory_size)}')\n",
    "    print(f'max taille en mémoire = {get_size_str(max_bytes)}')\n",
    "    sample_rate= max(1,round(memory_size/max_bytes))\n",
    "    sample_size = nb_registres if sample_rate==1 else round(nb_registres/sample_rate/10000) *10000\n",
    "    print(f'nb_colonnes = {df.shape[1]}')\n",
    "    print(f'nb_registres = {nb_registres}') \n",
    "    print(f'bytes_per_registre = {bytes_per_registre}')\n",
    "    print(f'sample_rate : 1 sur {sample_rate} registres')\n",
    "    print(f'sample_size = {sample_size}') \n",
    "    if memory_size < max_bytes:\n",
    "        return df\n",
    "    else:\n",
    "        return df.sample(sample_size)\n",
    "\n",
    "SAMPLE=False\n",
    "if SAMPLE:\n",
    "    # Utilise pour développer rapidement\n",
    "    data_df=sample_si_besoin(data_df, max_gigabytes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Nyk-Q_mBubI"
   },
   "source": [
    "### 2.4.2 Enregistre un échantillon pour développement local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WxfoVqiB1aX"
   },
   "outputs": [],
   "source": [
    "def save_sample(df, sample_filename='data_sample.csv', sample_size=100000):\n",
    "    \"\"\"Enregistre un échantillon de données pour développement local \"\"\"\n",
    "    sample_size = min(df.shape[0],sample_size)\n",
    "    if sample_size > 0:\n",
    "        (df.sample(sample_size)\n",
    "        .to_csv(os_path_join(OUT_FOLDER,sample_filename),sep='\\t',\n",
    "                encoding='UTF-8',index=False))\n",
    "\n",
    "SAVE_SAMPLE = not os.path.exists(os_path_join(OUT_FOLDER,SAMPLE_DATA_FILENAME))\n",
    "if SAVE_SAMPLE:\n",
    "    data_df.pipe(save_sample, sample_filename=SAMPLE_DATA_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvA5smsMgmEZ"
   },
   "source": [
    "## 2.4 Vérification et correction du typage des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRTNdNclgmEZ",
    "outputId": "896188de-2340-498c-cefa-6181ca14f610"
   },
   "outputs": [],
   "source": [
    "data_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1w593pKgmEZ"
   },
   "source": [
    "### 2.4.1 Converter _t en datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBVa1bIcgmEa",
    "outputId": "baf8caca-c802-4d3e-c6c0-6d4e18f36e68"
   },
   "outputs": [],
   "source": [
    "def convertir_to_datetime(df:pd.DataFrame):\n",
    "    df=df.copy()\n",
    "    date_cols=df.select_dtypes('datetime').columns\n",
    "    epoch_time_cols=df.columns[df.columns.str.endswith('_t')]\n",
    "    datetime_cols=df.columns[df.columns.str.endswith('_datetime')]\n",
    "    for col in epoch_time_cols:\n",
    "        if not col in date_cols:\n",
    "            print(f'convertir to datetime [{col}]')\n",
    "            df[col]=pd.to_datetime(df[col],utc=False,unit='s')\n",
    "    for col in datetime_cols:\n",
    "        if not col in date_cols:\n",
    "            print(f'convertir to datetime [{col}]')\n",
    "            df[col]=pd.to_datetime(df[col],utc=False,infer_datetime_format=True)\n",
    "    return df\n",
    "\n",
    "data_df=convertir_to_datetime(data_df)\n",
    "data_df.select_dtypes('datetime').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "AJ4eWS2TgmEa"
   },
   "source": [
    "### 2.4.1 Converter (_n, nova_group) en Int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "LhMMyJrYgmEa",
    "outputId": "06bbcf20-3783-43f0-fd1c-fb7f1baefffe"
   },
   "outputs": [],
   "source": [
    "def convertir_to_int(df:pd.DataFrame):\n",
    "    df=df.copy()\n",
    "    int_cols=df.columns[df.columns.str.endswith(('_n','nova_group'))]\n",
    "    for col in int_cols:\n",
    "        if col not in df.select_dtypes('Int64').columns:\n",
    "            print(f'convertir_to_int : [{col}] (type={df[col].dtype})')\n",
    "            col_as_int64=df[col].astype('Int64')\n",
    "            print(f'{col} as int64 is of type {col_as_int64.dtype}')\n",
    "            df[col]=pd.Series(df[col].array, dtype=\"Int64\")\n",
    "            print(f'{col} as int is of type {df[col].dtype}')\n",
    "    return df\n",
    "\n",
    "data_df=data_df.pipe(convertir_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "duEV6HwDgmEa"
   },
   "source": [
    "### 2.4.2 Trouver les variables catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPZ0kkUGgmEa",
    "outputId": "88939228-f185-48e2-c77d-6b972b21e17e"
   },
   "outputs": [],
   "source": [
    "data_df.select_dtypes('object').nunique().sort_values()[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpH2t276gmEa",
    "outputId": "f92d3ed6-2bf0-4fe4-d33b-b8ab69fb4d0d"
   },
   "outputs": [],
   "source": [
    "data_df.select_dtypes('category').nunique().sort_values()[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtsdzV8xgmEa"
   },
   "source": [
    "### Convertir les variables `nutriscore_grade`, `pnns_groups`, `nova_group`, etc en catégorique\n",
    "nova_group est considéré comme un variable quantitative\n",
    "Pour être traité comme variable catégorique il faut changer son type\n",
    "En mettant nutriscore_grade et nova_group comme catégorie, pandas est capable d'accélérer certaines analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wX1LHCiEgmEa",
    "outputId": "331761b7-efff-4438-ac69-51cc5c1758a1"
   },
   "outputs": [],
   "source": [
    "vars_categoriques = list(data_df.columns[data_df.columns.str.contains('_grade|_group',regex=True)])\n",
    "print(vars_categoriques)\n",
    "data_df[vars_categoriques].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8-mJ19egmEb",
    "outputId": "4df94a08-ae4e-4abf-abe6-3d74fa5ed85f"
   },
   "outputs": [],
   "source": [
    "def convertir_to_category(df, categ_cols=[], contient=['_group','_grade'], max_categs=50):\n",
    "    pattern='|'.join(contient)\n",
    "    df=df.copy()\n",
    "    filtre_match=df.columns.str.contains(pattern,regex=True)\n",
    "    filtre_unique=df[df.columns[filtre_match]].nunique() < max_categs\n",
    "    # colonnes_categoriques = list(df.columns[filtre_match])\n",
    "    colonnes_categoriques = list(df.columns[filtre_match][filtre_unique])\n",
    "    for col in (categ_cols + colonnes_categoriques):\n",
    "        if col in df.columns:\n",
    "            print(f'peut convertir_to_category, colonne [{col}]')\n",
    "            df[col]=df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "data_df=(data_df.pipe(convertir_to_category))\n",
    "data_df[vars_categoriques].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmBiBL4vgmEb",
    "outputId": "ae1b9252-78fe-4620-c85b-a49b7b4a433b"
   },
   "outputs": [],
   "source": [
    "data_df['pnns_groups_1'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YZtHh0kUgmEb",
    "outputId": "a91d8c8e-9279-43cf-9a91-ec1270fc882a"
   },
   "outputs": [],
   "source": [
    "(data_df[['pnns_groups_1','pnns_groups_2']].\n",
    "value_counts(normalize=True).to_frame(name='fréquence').reset_index().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f3-2QpfgmEb",
    "outputId": "ded506e4-fc43-4e01-ae03-97245676aded"
   },
   "outputs": [],
   "source": [
    "def remplacer_categories_unknown(df:pd.DataFrame, categ_cols=['pnns_groups_1','pnns_groups_2']):\n",
    "    df=df.copy()\n",
    "    for col in categ_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"remplace valeurs de categorie 'unknown' par NaN dans colonne [{col}]\")\n",
    "            df[col]=df[col].replace('unknown', np.NaN)\n",
    "    return df\n",
    "\n",
    "data_df=data_df.pipe(remplacer_categories_unknown);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG2sinaRgmEb"
   },
   "source": [
    "#### Corriger le type de nova_group (chaine, pas une valeur numérique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLEq3sNNgmEb",
    "outputId": "14a2429a-3f65-4c85-ad2b-6ddc173803fe"
   },
   "outputs": [],
   "source": [
    "def corrigir_nova_group(df):\n",
    "    if not 'nova_group' in df.columns: return df\n",
    "    print(df['nova_group'].dtype)\n",
    "    print(df['nova_group'].count())\n",
    "    df=df.copy()\n",
    "    df['nova_group']=df['nova_group'].astype(str)\n",
    "    df['nova_group']= df['nova_group'].str[0:1]\n",
    "    df['nova_group']=df['nova_group'].replace('n',pd.NA)\n",
    "    df['nova_group']=df['nova_group'].astype('category')\n",
    "    return df\n",
    "\n",
    "data_df=data_df.pipe(corrigir_nova_group)\n",
    "data_df['nova_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcEsTXYPgmEb",
    "outputId": "7c84ff9b-a1c8-4d14-b228-8d68ebd5d80f"
   },
   "outputs": [],
   "source": [
    "data_df['nova_group'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDLjdXMdgmEc",
    "outputId": "c20222da-03d0-47d2-e046-2d6ed4246adf"
   },
   "outputs": [],
   "source": [
    "data_df['nova_group'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjJiFiCkgmEc"
   },
   "outputs": [],
   "source": [
    "data_df.dtypes.to_csv(os_path_join(OUT_FOLDER, RAW_DATA_DICT),encoding='UTF-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "W9slLYWBgmEc",
    "outputId": "307edf1d-6438-407a-d3e7-fe209515cee5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)  # pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_rows', 10)  # pour afficher max 10 lignes\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "data_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9tzekIhgmEc"
   },
   "source": [
    "## 2.5 Pipeline pour corriger les types après import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYQEmnJjgmEc",
    "outputId": "bd941655-cbd0-4f57-d2f7-bd9823ed551d"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def pipeline_corriger_types(df):\n",
    "    print(f'pipeline_corriger_types, start_time={datetime.now().time():%H:%M:%S}')\n",
    "    return (df\n",
    "        .pipe(convertir_to_datetime)\n",
    "        .pipe(convertir_to_int)\n",
    "        .pipe(convertir_to_category,contient=['_group','_grade'])\n",
    "        .pipe(remplacer_categories_unknown)\n",
    "    )\n",
    "\n",
    "# data_df=data_df.pipe(pipeline_corriger_types)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKsgs6-axC9D"
   },
   "source": [
    "---\n",
    "\n",
    "# 3. Elimination de colonnes non-pertinentes et lignes dupliquées\n",
    "\n",
    "La base de données prend trop de RAM.\n",
    "\n",
    "On ne veut pas prendre un échantillon de registres (ex: seulement registres France)\n",
    "\n",
    "Donc, on élimine les colonnes non-pertinentes\n",
    "- colonnes vides\n",
    "- colonnes inutiles\n",
    "- colonnes en double (colonnes rédondantes)\n",
    "\n",
    "Puis, on élimine les lignes dupliquées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "GWRUrtvqgmEe"
   },
   "source": [
    "## 3.1 Suppression de colonnes vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgA96Go-CP9Y",
    "outputId": "a6d13566-a995-4f09-e4a3-2c27f5279b71"
   },
   "outputs": [],
   "source": [
    "def drop_colonnes_vides(df):\n",
    "    # return df.dropna(how='all', axis=1)\n",
    "    #colonnes_vides = df.columns[(df.count()==0)].to_list()\n",
    "    colonnes_vides = [col for col in df.columns if df[col].notnull().sum()==0]\n",
    "    print (f'drop  {len(colonnes_vides)} colonnes vides: drop {colonnes_vides}')\n",
    "\n",
    "    if (len(colonnes_vides) > 0) :\n",
    "        return df.drop(colonnes_vides, axis=1)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "print(f'data_df.shape avant: {data_df.shape}')\n",
    "data_df=data_df.pipe(drop_colonnes_vides)\n",
    "print(f'data_df.shape après: {data_df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "imjDeQRWgmEw"
   },
   "source": [
    "## 3.2 Élimination des colonnes inutiles<a name=\"colonnes-inutiles\"></a>\n",
    "- Colonnes sans nom\n",
    "- Colonnes identiques\n",
    "- Colonnes qui répètent la même information en plusieurs langues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54T3UU7LfxU9"
   },
   "source": [
    "### 3.2.1 Supprime colonnes sans nom\n",
    "\n",
    "Colonnes qui commence par `Unnamed` sont des colonnes 'index' produit par export pd.to_csv (avec `index=True`).\n",
    "\n",
    "Sur import, on ne sait pas comment cette index a était crée, donc on le supprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5qon_9bgmEf",
    "outputId": "2236f999-40e1-4ff1-a169-b4896f76c058"
   },
   "outputs": [],
   "source": [
    "def drop_colonnes_sans_nom(df:pd.DataFrame):\n",
    "    \"\"\"Colonnes qui commence par Unnamed sont en général des colonnes sans intérêt, produit par export pd.to_csv\"\"\"\n",
    "    unnamed_cols=list(df.columns[df.columns.str.startswith('Unnamed')])\n",
    "    print (f'drop unnamed colonnes : drop {unnamed_cols}')\n",
    "    if len(unnamed_cols) > 0:\n",
    "        return df.drop(unnamed_cols, axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df = data_df.pipe(drop_colonnes_sans_nom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd9vR0eEV_EM"
   },
   "source": [
    "### 3.2.2 Drop image URL colonnes\n",
    "\n",
    "Les colonnes des urls des images ne sont pas utiles pour l'analyse des additive, donc on les supprime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tgP3zPxV9aD",
    "outputId": "6136c21a-2d96-4b8a-bf3e-55b459047018"
   },
   "outputs": [],
   "source": [
    "def drop_colonnes_images_url (df:pd.DataFrame):\n",
    "    image_url_colonnes= df.columns[df.columns.str.endswith('_url')].to_list()\n",
    "    print(f'drop_colonnes_images_url: {image_url_colonnes}')\n",
    "    if len(image_url_colonnes)>0:\n",
    "        return df.drop(image_url_colonnes,axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df=data_df.pipe(drop_colonnes_images_url)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "EKgBmO8dgmEw"
   },
   "source": [
    "## 3.3 Élimination des colonnes rédondantes (idéntiques ou répetition des mêmes information)\n",
    "\n",
    "- La colonne 'url'\n",
    "- Les colonnes datetime et epoch_time\n",
    "- La colonne nutriscore_score et nutrition-score-fr_100g sont identiques\n",
    "- Les colonnes states, states_tags et states_en\n",
    "- Les colonnes countries, countries_tags, countries_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M6cm4yhgmEy"
   },
   "source": [
    "### 3.3.1 drop url colonne\n",
    "- l'url est composé de `http://world-en.openfoodfacts.org/product/` + `[code]` + kebab_case(`[product_name]-[brands_tags]`)\n",
    "- Le formatage du code dans l'url n'est pas standard :\n",
    "  - parfois ajout des 0 avant le code pour avoir un code de 13 chiffres\n",
    "  - parfois sans les 0\n",
    "  - parfois le brand est ajouté, parfois pas\n",
    "- Neanmoins, l'url crée à partir de la colonne `code` marche dasn tous les cas\n",
    "  - http://world-en.openfoodfacts.org/product/` + `[code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvvtwh1dT0yW"
   },
   "source": [
    "Donc, si on a besoin de trouver une item dans Openfoodfacts, on utilisera un query par code ou nom du produit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDP1iNvngmEy",
    "outputId": "cffb8838-bbc0-4623-ed8e-0ac6c40e2eb0"
   },
   "outputs": [],
   "source": [
    "def drop_colonne_url(df):\n",
    "    if 'url' in df.columns:\n",
    "        print('drop_colonne_url')\n",
    "        return df.drop('url',axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df=data_df.pipe(drop_colonne_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pT5i8EQEXGPv"
   },
   "source": [
    "### 3.3.2 Les colonnes datetime et epoch_time\n",
    "\n",
    "On verifie que les 2 colonnes sont identiques:\n",
    "- `created_t` vs `created_datetime`\n",
    "- `last_modified_t` vs `last_modified_datetime`\n",
    "\n",
    "Si c'est le cas, on garde la colonne `_datetime`, car la conversion est automatique pendant import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfbZI7osgmEx",
    "outputId": "71d6c6c4-74b2-47a4-d19e-e916c8bef42c"
   },
   "outputs": [],
   "source": [
    "def test_dates(df,col1,col2):\n",
    "    if col1 in df.columns and col2 in df.columns:\n",
    "        diff=df[col1]-df[col2]\n",
    "        return diff.max() - diff.min()\n",
    "\n",
    "print (test_dates(data_df,'created_t','created_datetime'))\n",
    "print (test_dates(data_df,'last_modified_t','last_modified_datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xjk3P0eZgmEx",
    "outputId": "7cdd6d4e-ffea-4e4c-cabf-6f20d067cd45"
   },
   "outputs": [],
   "source": [
    "def drop_colonnes_epoch_time(df):\n",
    "    epoch_time_cols= df.columns[df.columns.str.endswith('_t')].to_list()\n",
    "    if len(epoch_time_cols)>0:\n",
    "        print(f'drop_colonnes_epoch_time : {epoch_time_cols}')\n",
    "        return df.drop(epoch_time_cols,axis=1)\n",
    "    return df\n",
    "\n",
    "data_df= data_df.pipe(drop_colonnes_epoch_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ji7-Uzg5gmEx"
   },
   "source": [
    "### 3.3.3 Colonnes `nutriscore_score` et `nutrition-score-fr_100g`\n",
    "La version de la base contient 2 colonnes de nutriscore identique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUh0ehgW8TsH"
   },
   "outputs": [],
   "source": [
    "def cols_in_df(df:pd.DataFrame, colonnes:list=[])-> list:\n",
    "    \"\"\"procedure pour identifier les colonnes existants dans le dataframe\"\"\"\n",
    "    ret_cols=[]\n",
    "    for col in colonnes:\n",
    "        if col in df.columns:\n",
    "           ret_cols.append(col)\n",
    "    return ret_cols\n",
    "\n",
    "if len(cols_in_df(data_df,['nutriscore_score','nutrition-score-fr_100g'])) == 2:\n",
    "    data_df[['nutriscore_score','nutrition-score-fr_100g']].dropna().sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEvGE8ECCapt",
    "outputId": "747070e7-695b-43e1-cfae-e5ecfa1950a6"
   },
   "outputs": [],
   "source": [
    "def test_scores(df,col1,col2):\n",
    "    if col1 in df.columns and col2 in df.columns:\n",
    "        df=df[[col1,col2]].dropna()\n",
    "        diff=df[col1]-df[col2]\n",
    "        return diff.max() - diff.min()\n",
    "    else:\n",
    "        return (f'au moins une des colonnes {col1} et {col2} ne sont pas présent')\n",
    "\n",
    "print (test_scores(data_df,'nutriscore_score','nutrition-score-fr_100g'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lU9Nitt18V_Z",
    "outputId": "9e6e47e6-381c-4f63-8d8e-41157bdeb691"
   },
   "outputs": [],
   "source": [
    "def drop_score_cols_dupliques(df, col1='nutriscore_score', col2='nutrition-score-fr_100g'):\n",
    "    if col1 in df.columns and col2 in df.columns:\n",
    "        nb1=df[col1].isna().count()\n",
    "        nb2=df[col2].isna().count()\n",
    "        col_to_drop=col2 if nb2 >= nb1 else col1\n",
    "        print(f'drop_score_cols_dupliques, null count = {nb1} ({col1})')\n",
    "        print(f'drop_score_cols_dupliques, null count = {nb2} ({col2})')\n",
    "        print(f'drop_score_cols_dupliques, drop column [{col_to_drop}]')\n",
    "        return df.drop(col_to_drop, axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df = drop_score_cols_dupliques(data_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfI4533prEHU"
   },
   "source": [
    "### 3.3.4 Les colonnes states, state_tags et states_en\n",
    "\n",
    "On a vu que les colonnes de `states`, `states_tags` et `states_en` sont les plus volumineux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "kin-t0p-rCct",
    "outputId": "3ee95c07-9c30-49de-fc1e-eef9c29d768f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decrire_states(df):\n",
    "    states_cols=cols_in_df(df,['states','states_tags','states_en'])\n",
    "    states_df=df[states_cols]\n",
    "    states_unique=states_df.drop_duplicates()\n",
    "    print(len(states_unique)) \n",
    "    return states_df.describe()\n",
    "\n",
    "data_df.pipe(decrire_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miqjdmGqugOj",
    "outputId": "e98a83fd-0ee9-46d9-88e0-3058264683f8"
   },
   "outputs": [],
   "source": [
    "def drop_tag_cols_dupliques(df, cols=['states']):\n",
    "    df_cols= list(df.columns)\n",
    "    cols_to_drop=[]\n",
    "    for col in cols:\n",
    "        dup_tag_cols=[]\n",
    "        if f'{col}_en' in df_cols: dup_tag_cols.append(f'{col}_en')\n",
    "        if f'{col}_tags' in df_cols: dup_tag_cols.append(f'{col}_tags')     \n",
    "        if col in df_cols: dup_tag_cols.append(col)\n",
    "        if len(dup_tag_cols)>1:\n",
    "            print (f'keep [{dup_tag_cols[0]}], drop {dup_tag_cols[1:]}')\n",
    "            cols_to_drop += dup_tag_cols[1:]\n",
    "    return df.drop(cols_to_drop,axis=1)\n",
    "\n",
    "data_df=data_df.pipe(drop_tag_cols_dupliques,cols=['states']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "UzpCCUfggmEy"
   },
   "source": [
    "### 3.3.5 Les autres colonnes composées de listes de chaines, tags etc\n",
    "\n",
    "- https://world.openfoodfacts.org/data/data-fields.txt\n",
    "- inférence en regardant df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqkgjjFBgmEy",
    "outputId": "540ef660-0b0c-42fc-d1e0-5925998cf13c"
   },
   "outputs": [],
   "source": [
    "def find_list_colonnes(df:pd.DataFrame)-> list:\n",
    "    \"\"\"Liste des colonnes du dataframe qui contient des listes \"\"\"\n",
    "    cols= df.select_dtypes('object').columns.tolist()\n",
    "    ret=[]\n",
    "    for col in cols:\n",
    "        if col in ['product_name', 'abbreviated_product_name', 'generic_name']: continue \n",
    "        elif df[col].dropna().str.contains(',').any(): ret.append(col)\n",
    "    return ret\n",
    "\n",
    "tag_cols=find_list_colonnes(data_df)\n",
    "print(tag_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8vY7IvOkGf-"
   },
   "outputs": [],
   "source": [
    "list_cols= ['packaging', 'brands', 'categories','labels','countries','states', 'emb', 'main_category']\n",
    "\n",
    "def decrire_liste_cols(df,racine='countries'):\n",
    "   liste_cols=cols_in_df(df,[racine,f'{racine}_text',f'{racine}_tags',f'{racine}_en'])\n",
    "   liste_df= df[liste_cols].dropna(how='all')\n",
    "   print(liste_df.tail(1).T)\n",
    "   return liste_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "NJtAMlLek3Qg",
    "outputId": "502705a5-f217-4a00-e505-83c5b16e0405"
   },
   "outputs": [],
   "source": [
    "data_df.pipe(decrire_liste_cols,'brands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "KHtHQNjWgmEy",
    "outputId": "7a0b671e-b0c2-43a6-b555-9b85a085d213"
   },
   "outputs": [],
   "source": [
    "data_df.pipe(decrire_liste_cols,'categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "gAz52QI4mCU7",
    "outputId": "d8e952ff-9c9e-43ef-a152-4cfd441260df"
   },
   "outputs": [],
   "source": [
    "data_df.pipe(decrire_liste_cols,'countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "erhMvZ9tgmEy"
   },
   "source": [
    "On voit que la colonne de base est en plusieurs langues,\n",
    "qui explique pourquoi il y a plus de categories que de tags\n",
    "(qui sont en general avec prefix en:)\n",
    "\n",
    "- la colonne `categories_en` fournie la traduction anglaise des catégories\n",
    "\n",
    "Pour éliminer les données en duple ou triple :\n",
    "- garder la colonne qui termine avec `_en` s'il reste dans la base\n",
    "- sinon, garder la colonne qui termine avec `_tags`\n",
    "- sinon, garder la colonne de base\n",
    "\n",
    "On fera ça avec toutes les colonnes des tags : ['packaging', 'brands', 'categories','labels','countries','additives','states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oce4zgEVgmEz",
    "outputId": "02cf4ae9-012b-4add-8f72-976c36c83ed4"
   },
   "outputs": [],
   "source": [
    "def drop_tag_cols_dupliques(df, cols=['packaging', 'brands' 'categories','labels','countries','states']):\n",
    "    df_cols= list(df.columns)\n",
    "    cols_to_drop=[]\n",
    "    for col in cols:\n",
    "        dup_tag_cols=[]\n",
    "        if f'{col}_en' in df_cols: dup_tag_cols.append(f'{col}_en')\n",
    "        if f'{col}_tags' in df_cols: dup_tag_cols.append(f'{col}_tags')     \n",
    "        if col in df_cols: dup_tag_cols.append(col)\n",
    "        if len(dup_tag_cols)>1:\n",
    "            print (f'drop_tag_cols, keep [{dup_tag_cols[0]}], drop {dup_tag_cols[1:]}')\n",
    "            cols_to_drop += dup_tag_cols[1:]\n",
    "    if len(cols_to_drop)>0:\n",
    "        return df.drop(cols_to_drop, axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df=drop_tag_cols_dupliques(data_df);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "zX2xSuAggmEz"
   },
   "source": [
    "## 3.4 Pipeline pour éliminer les colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6d_SW3EgmEz",
    "outputId": "09ac60a5-e84d-4087-a275-d807e7e37b60"
   },
   "outputs": [],
   "source": [
    "\n",
    "def pipeline_eliminer_colonnes_inutiles(df):\n",
    "    print(f'pipeline_eliminer_colonnes_inutiles, start_time={datetime.now().time():%H:%M:%S}')\n",
    "    return (df\n",
    "            .pipe(drop_colonnes_vides)\n",
    "            .pipe(drop_colonnes_sans_nom)\n",
    "            .pipe(drop_colonnes_images_url)\n",
    "            .pipe(drop_colonne_url)\n",
    "            .pipe(drop_colonnes_epoch_time)\n",
    "            .pipe(drop_score_cols_dupliques)\n",
    "            .pipe(drop_tag_cols_dupliques,cols=['states'])\n",
    "            .pipe(drop_tag_cols_dupliques)\n",
    "            )\n",
    "\n",
    "data_df=data_df.pipe(pipeline_eliminer_colonnes_inutiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "IGwUSmpOgmEc"
   },
   "source": [
    "---\n",
    "\n",
    "## 3.5 Élimination des lignes dupliquées<a name=\"drop_dupliquees\"></a>\n",
    "\n",
    "L'élimination des lignes dupliquées dépend du problématique :\n",
    "   - Candidats et choix de la clé primaire\n",
    "   - Triage des dupliqués\n",
    "   - Visualisation du triage\n",
    "   - Pipeline pour éliminer les lignes dupliquées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "8l7JgZ9kgmEc"
   },
   "source": [
    "### 3.5.1 Colonnes candidates pour la clé primaire :\n",
    "\n",
    "La problématique est, donnée un produit, recommender des produits alternatifs.\n",
    "\n",
    "Donc candidats pour l'identité d'un produit sont :\n",
    "- code, url, product_name, abbreviated_product_name, generic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZSyMyB5gmEc",
    "outputId": "3f088aaf-807e-481d-a288-f0f608b96039"
   },
   "outputs": [],
   "source": [
    "def count_duplicates(df: pd.DataFrame, subset=['code']):\n",
    "    for col in subset:\n",
    "        if not col in df.columns:\n",
    "            print(f'count_duplicates ({subset}), column {col} not present in data')\n",
    "            return df\n",
    "    nb_dup=sum(df[subset].dropna().duplicated())\n",
    "    # nb_dup=sum(df.dropna(subset=subset).duplicated(subset=subset))\n",
    "    print(f'count_duplicates ({subset}) = {nb_dup}')\n",
    "    return df\n",
    "\n",
    "(data_df\n",
    " .pipe(count_duplicates, ['code'])\n",
    " .pipe(count_duplicates, ['url'])\n",
    " .pipe(count_duplicates, ['product_name'])\n",
    " .pipe(count_duplicates, ['product_name','brands_tags'])\n",
    " .pipe(count_duplicates, ['abbreviated_product_name'])\n",
    " .pipe(count_duplicates, ['generic_name'])\n",
    " );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "nWC36r9NgmEd",
    "outputId": "4ebf1eff-0ea4-437f-ae57-9894aa9a57ba"
   },
   "outputs": [],
   "source": [
    "def list_duplicates(df: pd.DataFrame, subset='product_name'):\n",
    "    for col in subset:\n",
    "        if not col in df.columns:\n",
    "            print(f'list_duplicates ({subset}), column {col} not present in data')\n",
    "            return df\n",
    "    return df[df.duplicated(subset=subset, keep=False)].value_counts(subset=subset).to_frame(name='count')\n",
    "    \n",
    "\n",
    "list_duplicates(data_df, subset=['product_name']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqHUNnKygmEd",
    "outputId": "fa37ee77-546a-44df-cdba-e7b2220f390f"
   },
   "outputs": [],
   "source": [
    "def duplicate_brand_products(df):\n",
    "    duplicate_brand_products = list_duplicates(data_df, subset=['product_name', 'brands_tags'])\n",
    "    print(len(duplicate_brand_products))\n",
    "    print(duplicate_brand_products.head(5))\n",
    "    return duplicate_brand_products.index\n",
    "\n",
    "duplicate_brand_products(data_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "DgEhCLmYgmEd"
   },
   "source": [
    "### 3.5.2 Choix de clé pour éliminer les registres dupliqués\n",
    "13% des noms des produits sont des registres dupliqués.\n",
    "\n",
    "- Par exemple, \"burger vegana\" (283 résultats) :\n",
    "  - <https://world.openfoodfacts.org/cgi/search.pl?search_terms=burger+vegana+bonarea&search_simple=1&action=process>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "58g9htf7gmEd",
    "outputId": "bb98107a-41e3-4c89-8962-e0957869f62e"
   },
   "outputs": [],
   "source": [
    "def query_burger(df):\n",
    "    burger = df.query(\"product_name == 'Burger vegana'\")\n",
    "    print(len(burger))\n",
    "    print(burger[['creator','code', 'product_name', 'brands_tags', 'quantity', 'categories_en', 'serving_quantity']].head())\n",
    "\n",
    "    return burger[burger['states_en'].str.contains('Nutrition facts completed') & burger['states_en'].str.contains(\n",
    "        'Categories completed')].head()\n",
    "\n",
    "query_burger(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "AoSWUqkUgmEd"
   },
   "source": [
    "### 3.5.3 Supprimer des duplicates basées sur leur état de remplissage\n",
    "\n",
    "Pour notre application, nos priorités pour remplissage des champs sont :\n",
    " - nom de produit (Product name completed)\n",
    " - données des additifs (Ingredients completed)\n",
    " - valeurs nutritionnels / nutriscore (Nutrition facts completed)\n",
    " - catégorie de produit / groupe PNNS (Categories completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "t9GVia42gmEd"
   },
   "source": [
    "#### 3.5.3.1 Triage de la base par priorité de remplissage\n",
    "- supprime les produits sans nom, puis trier par additifs_n, nutriscore_score, fat_100g, main_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkAEtahzgmEd",
    "outputId": "99b2892c-57c6-484a-a557-3027b8478452"
   },
   "outputs": [],
   "source": [
    "def sort_by_priority(df:pd.DataFrame):\n",
    "    cols=cols_in_df(df,['additives_n','main_category_en'])\n",
    "    ascend = tuple([False for col in cols])\n",
    "    return df.sort_values(by=cols, ascending=ascend)\n",
    "\n",
    "data_df=data_df.pipe(sort_by_priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "pgReRgZugmEe"
   },
   "source": [
    "#### 3.5.3.2 Visualiser l'état de remplissage de la base après triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "w_uJ1lgogmEe",
    "outputId": "7abfc70e-ee38-48c8-c3d5-985a8775ce59"
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "def plot_missing_matrix(df, cols=[\n",
    "    'additives_n','nova_group',\n",
    "    'nutriscore_score',\n",
    "    'main_category_en', 'pnns_groups_1', 'pnns_groups_2',\n",
    "    'fat_100g']):\n",
    "    msno.matrix(df[cols])\n",
    "\n",
    "# data_df.pipe(sort_by_points).pipe(plot_missing_matrix)\n",
    "sample_size=min(1000,len(data_df))\n",
    "data_df.sample(sample_size).sort_values(by=['additives_n','main_category_en']).pipe(plot_missing_matrix)\n",
    "\n",
    "#data_df.sample(sample_size).sort_values(by=['additives_n','nova_group','main_category_en','nutriscore_score','fat_100g']).pipe(plot_missing_matrix)\n",
    "#to_png('3.3.2_etat_remplissage_apres_triage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "avtGosxLgmEe"
   },
   "source": [
    "#### 3.5.3.3 Élimine les lignes dupliquées après triage par état de remplissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyZkBJJcgmEe",
    "outputId": "93dd5569-d2ae-44aa-cbb1-117ad2caa7d0"
   },
   "outputs": [],
   "source": [
    "def drop_lignes_dupliquees(df:pd.DataFrame, subset=['code']):\n",
    "    nb_avant= df.shape[0]\n",
    "    \"\"\"drop duplicates, en indiquant le clé (subset) et le nombre de lignes supprimés\"\"\"\n",
    "    df.drop_duplicates(subset=subset,keep='first',inplace=True)\n",
    "    nb_apres= df.shape[0]\n",
    "    print(f'drop_lignes_dupliquées[{subset}], nb. lignes supprimés = {(nb_avant - nb_apres)}')\n",
    "    return df\n",
    "\n",
    "data_df=data_df.pipe(drop_lignes_dupliquees,subset=['code'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "s21JBUdJgmHt",
    "outputId": "a534717c-1d69-440f-ebe3-a03e45b29c4a"
   },
   "outputs": [],
   "source": [
    "def get_duplicates_index(df,subset):\n",
    "    return df[df[subset].duplicated(keep=False)]\n",
    "\n",
    "#data_df=data_df.pipe(drop_lignes_dupliquees,subset=['product_name','brands'])\n",
    "\n",
    "def get_product_brand_duplicates(df):\n",
    "    duplicates= get_duplicates_index(data_df, subset=['product_name', 'brands_tags'])\n",
    "    print(len(duplicates))\n",
    "    return duplicates[['generic_name','product_name','brands_tags']].head()\n",
    "\n",
    "\n",
    "get_product_brand_duplicates(data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6bjCVoa4odk"
   },
   "source": [
    "#### 3.5.3.4 Si on supprime duplicates sur `[product_name, brand]`, tous les produits generiques comme 'poulet', 'spaghetti' seront reduit a une seule produit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vdwszor0uXDt",
    "outputId": "8bb6a2be-e1dd-494f-c89d-0a14cf282cbc"
   },
   "outputs": [],
   "source": [
    "def drop_duplicate_brand_products(df: pd.DataFrame):\n",
    "    duplicate_brand_products =df[['product_name','brands']].duplicated(keep=\"first\")\n",
    "    # mantient les produits qui peuvent être défini seulement par code, generic_name, ou ingredients par exemple\n",
    "    null_brand_products = df[['product_name','brands']].isna().all()\n",
    "    return df[~duplicate_brand_products | null_brand_products] \n",
    "    \n",
    "def drop_dup_brand_products(df: pd.DataFrame):\n",
    "    duplicate_brand_products =df.duplicated(subset=['product_name','brands'],keep=\"first\")\n",
    "    # mantient les produits qui peuvent être défini seulement par code, generic_name, ou ingredients par exemple\n",
    "    null_brand_products = df['product_name'].isnull() & df['brands'].isnull()\n",
    "    return df[~duplicate_brand_products | null_brand_products] \n",
    "\n",
    "def drop_dup_branded_products(df:pd.DataFrame):\n",
    "    filtre = (~df.duplicated(['product_name','brands_tags'],keep='first') \n",
    "        | ((df['product_name'].isnull()) & (df['brands_tags'].isnull())))\n",
    "    print(f'drop_dup_branded_products, nb = {filtre.sum()}')\n",
    "    return df[filtre]\n",
    "\n",
    "data_df = drop_dup_branded_products(data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "9qMdRyq0gmEe"
   },
   "source": [
    "## 3.6 Pipeline pour éliminer lignes dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ut7EvbPBgmEe",
    "outputId": "78b20af5-d93f-4ad0-befb-be80680f1aad"
   },
   "outputs": [],
   "source": [
    "def pipeline_eliminer_lignes_dupliquees(df):\n",
    "    print(f'pipeline_eliminer_lignes_dupliquees, start_time={datetime.now().time():%H:%M:%S}')\n",
    "    return(df\n",
    "        .pipe(sort_by_priority)\n",
    "        .pipe(drop_lignes_dupliquees,subset=['code'])\n",
    "        .pipe(drop_dup_branded_products)\n",
    "        .pipe(drop_lignes_dupliquees,subset=['product_name','brands_tags'])\n",
    "    )\n",
    "\n",
    "data_df=data_df.pipe(pipeline_eliminer_lignes_dupliquees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "KVOfpsSAgmEe"
   },
   "source": [
    "# 4. Étude des valeurs manquantes<a name=\"valeurs-manquants\"></a>\n",
    "\n",
    "Les valeurs manquantes peuvent être imputés si on a assez de données dans la colonne,\n",
    "et que les valeurs aberrantes ont étés traités. Sinon, la colonne n'est pas utilisable.\n",
    "\n",
    "Dans cette premiere partie :\n",
    "   - Suppression de colonnes vides\n",
    "   - Remplissage des colonnes\n",
    "   - Valeur 'unknown' est une valeur manquante : le remplace avec la valeur 'null' / NaN\n",
    "   - Suppression de colonnes trop vides\n",
    "   - Analyse de la distribution des valeurs manquantes (corrélation entre colonnes)\n",
    "   - Pipeline pour traiter valeurs manquantes (partie 1)\n",
    "\n",
    "Après traitement de valeurs aberrantes, on traitera les valeurs manquantes par imputation (partie 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "0nh6dmhHgmEf"
   },
   "source": [
    "## 4.2 Remplissage des colonnes\n",
    "\n",
    "### 4.2.1 Taux de remplissage des colonnes des 'additifs'\n",
    "\n",
    "Notre colonne d'intérêt est le nombre d'additifs : Quel est sont taux de remplissage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f20e2djGgmEf",
    "outputId": "09fc1c92-a059-4f22-9e2c-1c1f167d92de"
   },
   "outputs": [],
   "source": [
    "def taux_remplissage(df,col):\n",
    "    total=len(df)\n",
    "    cpt=df[col].count()\n",
    "    print (f'\"{col}\": {cpt} ({round(100* cpt / total)}%)')\n",
    "    return df\n",
    "\n",
    "(data_df\n",
    "    .pipe(taux_remplissage,'additives_n')\n",
    "    .pipe(taux_remplissage,'additives_tags'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "k9YelQA0gmEf"
   },
   "source": [
    "### 4.2.2 Taux de remplissage des autres colonnes\n",
    "\n",
    "On cherche des colonnes avec un taux de remplissage similaire ou plus que nos colonnes des additifs.\n",
    "On define le niveau minimum de remplissage à 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "YBQq80t8gmEf"
   },
   "source": [
    "#### 4.2.2.1 Remplissage comme bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "PYtLaRCNgmEf",
    "outputId": "d5d8b1b5-229c-4a63-82f7-0386cd85fbcd"
   },
   "outputs": [],
   "source": [
    "def plot_bar_remplissage(df:pd.DataFrame, nb=50, titre=None, figsize=(10,10)):\n",
    "    nb = min(nb,df.shape[1])\n",
    "    ret= round((1-df.isna().mean())*100).sort_values(ascending=False)[:nb]\n",
    "    plt.figure(figsize=figsize)\n",
    "    taux = [f'>= {x//7 * 7}' for x in ret.values]\n",
    "    ax=sns.barplot(y=ret.index, x=ret.values, hue=taux, dodge=False)\n",
    "    ax.set_xlabel('Pourcent remplissage (%)', size=16)\n",
    "    ax.set_ylabel('Nom de la colonne', size=16)\n",
    "    ax.axvline(20, linestyle='--',color='red')\n",
    "    if titre is None:\n",
    "        titre = f'Taux de remplissage des {nb} colonnes plus remplis'\n",
    "    ax.set_title(label=f'{titre} [nb={df.shape[0]}]',size=20)\n",
    "    plt.legend(title='remplissage (%)')\n",
    "    sns.despine()\n",
    "\n",
    "plot_bar_remplissage(data_df)\n",
    "to_png('4.2.2.1_taux_remplissage_colonnes_bar')\n",
    "# show_bar_count(data_df)[10:50].plot(kind='bar')\n",
    "# data_df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTCWKM8OgmEg"
   },
   "source": [
    "#### 4.2.2.2 Remplissage comme colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "GxMrMlOegmEg",
    "outputId": "9d75669d-6586-4988-b7fb-5f57cb329391"
   },
   "outputs": [],
   "source": [
    "def plot_colonne_remplissage(df:pd.DataFrame, titre='remplissage', figsize=None, head=True, max_colonnes=100):\n",
    "    \"\"\"Affiche la remplissage de chaque colonne\"\"\"\n",
    "    remplissage = (round((1-df.isna().mean())*100)\n",
    "                    .sort_values(ascending=False)\n",
    "                    .to_frame(name='taux')\n",
    "                    .rename_axis('colonne').reset_index())\n",
    "    if head:\n",
    "        remplissage = remplissage.head(max_colonnes)\n",
    "    else:\n",
    "        nb_colonnes = len(remplissage)\n",
    "        if nb_colonnes > max_colonnes:\n",
    "            remplissage = remplissage.tail(max_colonnes - nb_colonnes)\n",
    "\n",
    "    remplissage['hue']= remplissage['taux']//7 * 7\n",
    "    remplissage['hue'] = '>= ' + remplissage['hue'].astype(str)\n",
    "    \n",
    "    _, ax = plt.subplots(figsize=figsize)\n",
    "    ax=sns.barplot(data=remplissage, ax=ax, x='colonne', y='taux',\n",
    "         hue='hue', dodge=False )\n",
    "    ax.set_xlabel('Nom de la colonne', size=16)\n",
    "    ax.set_ylabel('Pourcent remplissage (%)', size=16)\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.axhline(20, linestyle='--',color='red')\n",
    "    ax.set_title(label=f'{titre} [nb={df.shape[0]}]', size=20)\n",
    "    plt.legend(title='remplissage (%)')\n",
    "    sns.despine()\n",
    "\n",
    "max_cols= min(data_df.shape[1],60)\n",
    "plot_colonne_remplissage(\n",
    "    data_df, \n",
    "    titre=f'Taux de remplissage des colonnes (pour les {max_cols} colonnes plus remplis)',\n",
    "    figsize=(20, 5), \n",
    "    max_colonnes=max_cols\n",
    ")\n",
    "to_png('4.2.2.2_taux_remplissage_colonnes_barplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "hsXGc56JgmEg"
   },
   "source": [
    "## 4.3 Drop colonnes avec moins de 20% remplissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cip_kGgegmEg"
   },
   "outputs": [],
   "source": [
    "keep_columns=['ingredients_from_palm_oil_tags',\n",
    " 'ingredients_that_may_be_from_palm_oil_tags',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZUfhsBZgmEg"
   },
   "outputs": [],
   "source": [
    "def drop_colonnes_trop_vides(df:pd.DataFrame, threshold=0, keep_cols=[]):\n",
    "    \"\"\"supprime les colonnes, sauf des colonnes dans la liste de colonnes à retenir\"\"\"\n",
    "    cols=list(set(df.columns.to_list()) - set(keep_cols))\n",
    "    freq = 1-df[cols].isnull().mean()\n",
    "    colonnes_trop_vides = freq[freq <= threshold]\n",
    "    drop_cols=colonnes_trop_vides.sort_values(ascending=True).index.tolist()\n",
    "    total = len(df)\n",
    "    txt=f'drop_colonnes_vides, threshold = {threshold}, drop {len(drop_cols)} colonnes: '\n",
    "    for col in drop_cols:\n",
    "        cpt=df[col].count()\n",
    "        txt += f'\"{col}\": {cpt} ({round(100* cpt / total)}%); '\n",
    "    print (txt)   \n",
    "    return df.drop(colonnes_trop_vides.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cP7WrJ86PkS",
    "outputId": "ecdcb262-1890-4b83-d522-406af08a4da9"
   },
   "outputs": [],
   "source": [
    "data_df=data_df.pipe(drop_colonnes_trop_vides, threshold=0.05, keep_cols=keep_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t91nDf2SEzAb",
    "outputId": "9ab2cf6d-1101-475a-b865-05b12a9bd5b7"
   },
   "outputs": [],
   "source": [
    "data_df=data_df.pipe(drop_colonnes_trop_vides, threshold=0.1, keep_cols=keep_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "G0M8CzIVgmEh"
   },
   "source": [
    "## 4.4 Pipeline pour traiter les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7_QG92zgmEh",
    "outputId": "73cfc891-28c9-4e0a-bacb-a61eff78a510"
   },
   "outputs": [],
   "source": [
    "def pipeline_traiter_valeurs_manquantes(df):\n",
    "    print(f'pipeline_traiter_valeurs_manquantes, start_time={datetime.now().time():%H:%M:%S}')\n",
    "\n",
    "    # Notre intérêt est des additifs\n",
    "    keep_columns=cols_in_df(df,['ingredients_from_palm_oil_tags',\n",
    "                                'ingredients_that_may_be_from_palm_oil_tags'])\n",
    "    return (df\n",
    "           #.pipe(drop_unnamed_colonnes)\n",
    "           .pipe(drop_colonnes_vides)\n",
    "           .pipe(drop_colonnes_trop_vides, threshold=0.05, keep_cols=keep_columns)\n",
    "           .pipe(drop_colonnes_trop_vides, threshold=0.10, keep_cols=keep_columns)\n",
    "           .pipe(drop_colonnes_trop_vides, threshold=0.15, keep_cols=keep_columns)\n",
    "           .pipe(drop_colonnes_trop_vides, threshold=0.20, keep_cols=keep_columns)\n",
    "           )\n",
    "\n",
    "data_df = (data_df\n",
    "               .pipe(pipeline_traiter_valeurs_manquantes)\n",
    "               )\n",
    "print(f'shape : {data_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b5xqd5FgmEh",
    "outputId": "b7dfbb12-c64a-4262-f308-795ae4005178"
   },
   "outputs": [],
   "source": [
    "print(list(data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "swhZNZc-gmEh"
   },
   "source": [
    "## 4.5. Analyse de la distribution des valeurs manquantes\n",
    "Le graphique de taux remplissage montre des groupes de taux de remplissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUpdMny1gmEh",
    "outputId": "97389847-fcc0-490f-d8d0-7b5054e5daec"
   },
   "outputs": [],
   "source": [
    "def liste_percent_remplissage(df):\n",
    "    return ((1 - df.isnull().mean()) * 100).sort_values(ascending=False)\n",
    "\n",
    "taux=liste_percent_remplissage(data_df)\n",
    "print(taux)\n",
    "print(taux.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2tacB4UgmEh"
   },
   "outputs": [],
   "source": [
    "\n",
    "analyse_cols = data_df.pipe(cols_in_df,[\n",
    "     'creator','countries_en',\n",
    "      # colonnes nutritionnels\n",
    "     'energy_100g', 'fat_100g', 'carbohydrates_100g', 'proteins_100g', 'sugars_100g','saturated-fat_100g','sodium_100g',\n",
    "     'nutriscore_score', 'nutriscore_grade', 'nutrition-score-fr_100g',\n",
    "      'ingredients_text','ingredients_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_n', 'additives_n',\n",
    "      'nova_group',\n",
    "      'main_category_en', 'categories_en',\n",
    "      'pnns_groups_1', 'pnns_groups_2',\n",
    "      'ecoscore_grade_fr', 'brands'\n",
    "      ])\n",
    "\n",
    "to_analyse=data_df[analyse_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "Uc5tNTvngmEi",
    "outputId": "546d48bd-077b-44b0-b390-cdc4514f6b3b"
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "\n",
    "to_analyse=to_analyse.sort_values(by=cols_in_df(to_analyse,[\n",
    "    'ingredients_that_may_be_from_palm_oil_n', # ingredients\n",
    "    'nutriscore_grade',                        # nutrition\n",
    "    'pnns_groups_1','main_category_en',        # category\n",
    "    'nova_group',\n",
    "'sodium_100g','fat_100g','energy_100g',]))\n",
    "msno.matrix(to_analyse)\n",
    "to_png('4.5_distribution_des_valeurs_manquantes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "azY55noogmEi"
   },
   "source": [
    "### 4.5.1 Analyse des données manquantes par contributeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "adrs1QFjgmEi",
    "outputId": "cc9e8234-7c67-483a-b9a5-c4c77f9c4213"
   },
   "outputs": [],
   "source": [
    "top_contributeurs = (to_analyse['creator'].value_counts(normalize=True)\n",
    "    .to_frame(name='freq').head(7))\n",
    "top_contributeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J1di5naPgmEi",
    "outputId": "92af3154-771b-4a69-a730-ec2cfca92067"
   },
   "outputs": [],
   "source": [
    "for contributeur in top_contributeurs.index.to_list():\n",
    "    anal=to_analyse[to_analyse['creator']==contributeur]\n",
    "    msno.matrix(anal)\n",
    "    plt.gca().set_title(label=f'Remplissage par contributeur :{contributeur}',size=24)\n",
    "    to_png(f'4.5.1_remplissage_par_contributeur_{contributeur}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "4TFlI2O1gmEi"
   },
   "source": [
    "### 4.5.2 Analyse des données manquantes par pays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "lm8haBDTgmEi"
   },
   "source": [
    "#### Unique values from a tags column\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "my_df=pd.DataFrame(['a,b,c','d,e','f'], columns={'some_tags_column'})\n",
    "my_df['some_tags_column'].str.split(',', expand=True).stack().unique().tolist()\n",
    "```\n",
    "Simplifier avec `explode_series(my_df[col]).unique().tolist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMxFe8dOgmEi"
   },
   "outputs": [],
   "source": [
    "def explode_series(series:pd.Series) -> pd.Series:\n",
    "    \"\"\"convertir ['a,b,c','d,e','f']--> ['a','b','c','d','e','f']  \"\"\"\n",
    "    if series.str.contains(',').any():\n",
    "        return series.str.split(',').explode()\n",
    "    else:\n",
    "        return series.explode()\n",
    "\n",
    "def top_tags(df,col,normalize=True, nb=7):\n",
    "    return (explode_series(df[col])\n",
    "            .value_counts(normalize=normalize)\n",
    "            .to_frame(name='freq').head(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D6rEVK14gmEj",
    "outputId": "d1759844-0c4c-45b8-a65b-f485fe7f469e"
   },
   "outputs": [],
   "source": [
    "def remplissage_par_pays(df=to_analyse, nb=5):\n",
    "    df2=df.dropna(subset=['countries_en'])\n",
    "    top_pays=top_tags(df2,col='countries_en',nb=nb)\n",
    "    for pays in top_pays.index.to_list():\n",
    "        anal_pays=df2[df2['countries_en'].str.contains(pays)]\n",
    "        msno.matrix(anal_pays)\n",
    "        plt.gca().set_title(label=f'Remplissage par pays :{pays}',size=24)\n",
    "        to_png(f'4.5.2_remplissage_par_pays_{pays}')\n",
    "\n",
    "remplissage_par_pays(to_analyse, nb=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVPmoonwgmEj"
   },
   "source": [
    "Intéressant, la distribution de remplissage des champs varie beaucoup entre les pays\n",
    "Additives(ingredients) \n",
    "- presque complet pour produits d'Etats Unis\n",
    "- bien remplis pour Allemagne\n",
    "- mal remplis pour la France\n",
    "- presque pas remplis pour les produits d'Espagne et d'Italie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsBF-V6oTjKZ"
   },
   "outputs": [],
   "source": [
    "to_analyse=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "gF9S129sgmEj"
   },
   "source": [
    "### Conclusion de l'analyse de données manquantes\n",
    "\n",
    "Les données fournies par chaque contributeur sont groupées :\n",
    "- les ingredients (qui inclut les additifs)\n",
    "- les valeurs nutritionnelles\n",
    "- les categories / groupes PNNS\n",
    "- le 'nova' group\n",
    "- le nutriscore\n",
    "- l'ecoscore\n",
    "- les brands\n",
    "\n",
    "Notre intérêt est comment éviter les mauvais additifs\n",
    "1. un nouvel indicateur de niveau d'additifs méritant attention\n",
    "2. voir si on peut éviter les additifs en choisissant le meilleur nutriscore\n",
    "3. voir si on peut éviter les additifs en évitant certain brands\n",
    "4. voir si on peut éviter les additifs en évitant certain categories/ groupes PNNS\n",
    "\n",
    "Ces critères seront utilisés pour développer un système de recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "tk9Am0JVgmEj"
   },
   "source": [
    "# 5. Nettoyage des valeurs aberrantes<a name=\"valeurs-aberrants\"></a>\n",
    "\n",
    "On inspire sur les contrôles de qualité de données d'Openfoodfacts\n",
    "- <https://github.com/openfoodfacts/openfoodfacts-server/blob/main/taxonomies/data_quality.result.txt>\n",
    "\n",
    "Les valeurs aberrantes considérées sont :\n",
    "- produits qui ne sont pas de nourriture / sans nom : les élimine\n",
    "- valeurs nutritionnelles < 0\n",
    "- valeurs nutritionnelles > 100 g per serving de 100 g\n",
    "- la somme des valeurs nutritionnelles pour 100 g > 100 g.\n",
    "- sucres + amidon > glucides\n",
    "- énergie pour 100 g > 3800 kJ, ce qui n'est pas possible.\n",
    "- énergie kcal > (énergie en kJ / 4.184)\n",
    "- whitespace (colonne 'product_name' par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "DJQLVZwUgmEj"
   },
   "source": [
    "## 5.1 Produits qui ne sont pas de nourriture / sans nom\n",
    "\n",
    "### 5.1.1 Supprimer les produits sans nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN7gj04OgmEj",
    "outputId": "cdd8cda9-2625-4f09-fdd6-0f28b4009b23"
   },
   "outputs": [],
   "source": [
    "print(data_df['product_name'].isnull().sum())\n",
    "data_df= data_df.dropna(subset=['product_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "7oTo5PWugmEj"
   },
   "source": [
    "### 5.1.2 Trouver produits aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUp9eQFdgmEj",
    "outputId": "420e6f7e-91b9-422e-930c-fb363a848205"
   },
   "outputs": [],
   "source": [
    "NONE_FOOD_WORD_LIST: list = ('non food,dog food,bird food,cat food,pour chien,pour chat,'\n",
    "                             + 'shampoo,savon,dentifrice,toothpaste,transpirant,nivea,garnier,beauty,visage,'\n",
    "                             + 'detergent,vaisselle,wash,cleaner,softener,adoucissant,lessive,éponge,'\n",
    "                             + 'clothes,books,kitchenware,medicine,poubelle').split(',')\n",
    "\n",
    "# categories à exclure de la recherche\n",
    "FOOD_CATEGORIES: list = ['cheeses']  # exemple: 'washed-rind cheeses'\n",
    "\n",
    "\n",
    "def liste_non_foods(df: pd.DataFrame, col='product_name', non_foods=NONE_FOOD_WORD_LIST, \n",
    "            food_categories=FOOD_CATEGORIES, nb=20):\n",
    "    \"\"\"Trouver les produits qui ne sont pas des aliments\"\"\"\n",
    "    if not col in df.columns:\n",
    "         \"\"\"retourné dataframe vide\"\"\"\n",
    "         return pd.DataFrame([],columns=df.columns) \n",
    "    non_foods = '|'.join(non_foods)\n",
    "    food_categories = '|'.join(food_categories)\n",
    "    # tagged 'Non food product'\n",
    "    filtre_tagged_non_food = df['categories_en'].fillna(\n",
    "        '').str.contains('non food', case=False, regex=True)\n",
    "    # chercher d'autres produits qui ne sont pas alimentation\n",
    "    filtre_non_foods = df[col].fillna('').str.contains(\n",
    "        non_foods, case=False, regex=True)\n",
    "    # eviter d'inclure les food categories qui contient les mots des non foods\n",
    "    filtre_foods = df['categories_en'].fillna('').str.contains(\n",
    "        food_categories, case=False, regex=True)\n",
    "    filtre = filtre_tagged_non_food | (~filtre_foods & filtre_non_foods)\n",
    "    print(f'liste_non_foods [{col}] (nb={filtre.sum()})')\n",
    "    non_food_df = df[filtre]\n",
    "\n",
    "    filtre_washington=non_food_df['product_name'].fillna('').str.contains('washington',case=False)\n",
    "    non_food_df=non_food_df[~filtre_washington]\n",
    "    # print(f'{non_food_df[col].unique()[:nb].tolist()}')\n",
    "    return non_food_df\n",
    "\n",
    "def trouve_non_food(df):\n",
    "    \"\"\"liste les non_food trouver par mot clé dans plusieurs colonnes. \n",
    "       On utilise index.name du dataframe pour identifier le dataframe \n",
    "       retourné par liste_non_foods: Il ne doit pas avoir le nom d'un des colonnes\"\"\"\n",
    "    non_food_categ = data_df.pipe(\n",
    "        liste_non_foods, col='categories_en').rename_axis('categ')\n",
    "    non_food_main_categ = data_df.pipe(\n",
    "        liste_non_foods, col='main_category_en').rename_axis('main_categ')\n",
    "    non_food_brands = data_df.pipe(\n",
    "        liste_non_foods, col='brands_tags').rename_axis('brand')\n",
    "    non_food_products = data_df.pipe(\n",
    "        liste_non_foods, col='product_name').rename_axis('product')\n",
    "\n",
    "    def not_in_dataframe(df1: pd.DataFrame, df2: pd.DataFrame, nb=10):\n",
    "        \"\"\"trouve les (non-food) produits dans df1 qui ne sont pas dans df2\"\"\"\n",
    "        ret = df1[~df1.index.isin(df2.index)]\n",
    "        print(\n",
    "            f'produits dans {df1.index.name} pas dans {df2.index.name}: {len(ret)}')\n",
    "        # print(ret['product_name'].value_counts().index[:nb].tolist())\n",
    "        return ret\n",
    "\n",
    "    # Produits trouvés par filtre sur 'main_category' mais pas par 'product_name'\n",
    "    for df1 in [non_food_categ, non_food_main_categ, non_food_brands, non_food_products]:\n",
    "        for df2 in [non_food_categ, non_food_main_categ, non_food_brands, non_food_products]:\n",
    "            if df1.index.name != df2.index.name:\n",
    "                not_in_dataframe(df1, df2)\n",
    "    return non_food_products\n",
    "\n",
    "non_food_products = data_df.pipe(trouve_non_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "F-h25QJSgmEk",
    "outputId": "73e0b67f-f126-47d7-f9c9-201defe7f57d"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30) \n",
    "explode_series(non_food_products['main_category_en']).value_counts().to_frame()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "2FvIpe2wgmEk",
    "outputId": "966f3d74-6b68-424c-a9ba-30e285af1e0e"
   },
   "outputs": [],
   "source": [
    "nb=len(non_food_products)\n",
    "non_food_products[['product_name','brands','categories_en', 'main_category_en']].sample(min(nb,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Q6wK2PSgmEk",
    "outputId": "0754c832-26d9-4ee2-ea7e-ecc08946826c"
   },
   "outputs": [],
   "source": [
    "def list_additif_counts(df):\n",
    "  return (df['additives_en'].dropna().str.split(',')\n",
    "  .explode().value_counts().head(20))\n",
    "\n",
    "list_additif_counts(non_food_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5oQS8u4YmEL",
    "outputId": "b262513b-05f0-4d1b-9692-1cf91f226aa4"
   },
   "outputs": [],
   "source": [
    "def list_maybe_food(df):\n",
    "    maybe_food=df[df['additives_en'].fillna('').str.contains('Citric acid')]\n",
    "    print(maybe_food['product_name'].unique()[:10])\n",
    "\n",
    "list_maybe_food(non_food_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uk3sYotucXH6"
   },
   "outputs": [],
   "source": [
    "del non_food_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "IF1nIK0sgmEk"
   },
   "source": [
    "### 5.1.3 Supprimer les produits aberrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5Do9Zb9gmEk",
    "outputId": "a65c180e-0611-4f9a-efc5-fdb83ea81e39"
   },
   "outputs": [],
   "source": [
    "def drop_non_foods(df, col='product_name',non_foods=NONE_FOOD_WORD_LIST,food_categories=FOOD_CATEGORIES,showlist=False):\n",
    "    non_foods_df=liste_non_foods(df,col,non_foods=non_foods,food_categories=food_categories )\n",
    "    print(f'drop_non_foods [{col}], nb={len(non_foods_df)}')\n",
    "    if showlist:\n",
    "        print(f'{non_foods_df[col].unique().tolist()[:20]}')\n",
    "    return df.drop(non_foods_df.index)\n",
    "\n",
    "data_df=data_df.pipe(drop_non_foods,col='product_name',showlist=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "q73HbKvrgmEk"
   },
   "source": [
    "## 5.2 Valeurs nutritionnelles aberrantes (<0 ou > 100 pour 100 g)\n",
    "- valeur nutritionnelle < 0\n",
    "- valeur nutritionnelle > 100 pour 100 g\n",
    "\n",
    "## 5.2.1 Liste les colonnes nutritionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pk8goQuVgmEk",
    "outputId": "3b998b7f-f52f-419f-aa7c-b36c2cb9586d"
   },
   "outputs": [],
   "source": [
    "def get_colonnes_nutritionnelles_100g(df:pd.DataFrame)-> list:\n",
    "    servings = df.columns.str.endswith('_100g')\n",
    "    not_servings = (df.columns.str.contains('score|footprint|energy', regex=True))\n",
    "    ret = df.columns[servings & ~not_servings]\n",
    "    return ret.tolist()\n",
    "\n",
    "col_servings = get_colonnes_nutritionnelles_100g(data_df)\n",
    "col_servings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "q5-rFq-rgmEl"
   },
   "source": [
    "### 5.2.2 Souligne les colonnes avec des valeurs < 0 ou valeurs > 100 per 100 g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "Onp3QC-tgmEl",
    "outputId": "c76a3944-922a-48c5-e857-eb9062071cbe"
   },
   "outputs": [],
   "source": [
    "def get_servings_colonnes_min_max(df:pd.DataFrame)->pd.DataFrame:\n",
    "    servings_colonnes = get_colonnes_nutritionnelles_100g(df)\n",
    "    return df[servings_colonnes].agg([min, max]).T\n",
    "\n",
    "def is_negative(cell_value, color='pink'):\n",
    "    return f'background-color: {color};' if cell_value < 0 else None\n",
    "\n",
    "def is_over100(cell_value, color='#FF99FF'):\n",
    "    return f'background-color: {color};' if cell_value > 100 else None\n",
    "\n",
    "(get_servings_colonnes_min_max(data_df).style\n",
    "     .applymap(is_over100, subset=['max'])\n",
    "     .applymap(is_negative, subset=['min'])\n",
    "     .set_precision(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "1OxUL7lcgmEl"
   },
   "source": [
    "### 5.2.2 Drop lignes avec valeurs nutritionnelles < 0 ou valeurs nutritionnelles > 100 per 100 g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "xVnuFNLmgmEl",
    "outputId": "6a087483-965d-483b-a525-7708d080ef0d"
   },
   "outputs": [],
   "source": [
    "def get_aberrant_valeurs_nutritionnelles(df):\n",
    "    servings = get_colonnes_nutritionnelles_100g(df)\n",
    "    # servings avec valeurs < 0 ou > 100\n",
    "    serv = df[servings].agg([min, max]).T\n",
    "    aberrant_cols = serv[(serv['min'] < 0) | (serv['max'] > 100)].index\n",
    "    if len(aberrant_cols) > 1:\n",
    "        filtre = False\n",
    "        for col in aberrant_cols:\n",
    "            filtre |= (df[col] < 0) | (df[col] > 100)\n",
    "        aberrant_rows = df[filtre]\n",
    "    else:\n",
    "        aberrant_rows = df[df['code']==-1]\n",
    "\n",
    "    print(f'get_aberrant_valeurs_nutritionnels, nb={len(aberrant_rows)}')\n",
    "    colonnes = cols_in_df(df,['code', 'product_name', 'brands','brands_tags']) + aberrant_cols.tolist()\n",
    "    return aberrant_rows[colonnes]\n",
    "\n",
    "data_df.pipe(get_aberrant_valeurs_nutritionnelles).head(5).style.set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIu2zo7BgmEl",
    "outputId": "3df1564a-a672-4fdc-bbbc-fa8d8d72837a"
   },
   "outputs": [],
   "source": [
    "def drop_aberrant_valeurs_nutritionnelles(df):\n",
    "    aberrant_rows = get_aberrant_valeurs_nutritionnelles(df)\n",
    "    print(f'drop_aberrant_valeurs_nutritionnelles, nb registres aberrants : {len(aberrant_rows)}')\n",
    "    if len(aberrant_rows)>0:\n",
    "        return df.drop(aberrant_rows.index)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "data_df = data_df.pipe(drop_aberrant_valeurs_nutritionnelles);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "tTWQ8iDCgmEl"
   },
   "source": [
    "## 5.3 Somme des valeurs nutritionnelles > 105 g per serving de 100 g\n",
    "\n",
    "On met la limite à 105 g (pas 100 g) pour la somme, car les valeurs peuvent être arrondies (65.51 -> 66)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "9l9Fg9lCgmEm",
    "outputId": "19555db3-eaa4-4c4a-b6d9-2e554f7fc1da"
   },
   "outputs": [],
   "source": [
    "def get_sum_valeur_nutritionnelle_trop_grand(df:pd.DataFrame):\n",
    "    servings = cols_in_df(df,['fat_100g','sugars_100g','fiber_100g','proteins_100g','salt_100g'])\n",
    "    filtre_ignore_incomplete= df[servings].notnull().all(1) \n",
    "    filtre_total_trop_grand =  df[servings].sum(axis=1) >= 105 \n",
    "    filtre= filtre_ignore_incomplete & filtre_total_trop_grand\n",
    "    nb_rows= filtre.sum()\n",
    "    print(f'get_sum_valeur_nutritionnelle_trop_grand, nb registres ou total(servings)=0 : {nb_rows}')\n",
    "    example=df[filtre][servings].head(5)\n",
    "    print(f'example :\\n{example}')\n",
    "    return df[filtre]\n",
    "\n",
    "data_df.pipe(get_sum_valeur_nutritionnelle_trop_grand)[['product_name','main_category_en']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4hSpudagmEm",
    "outputId": "935e3feb-adc8-43e5-a03f-ab40c158b7e2"
   },
   "outputs": [],
   "source": [
    "def drop_aberrant_servings(df:pd.DataFrame):\n",
    "    aberrant_servings = get_sum_valeur_nutritionnelle_trop_grand(df)\n",
    "    return df.drop(aberrant_servings.index)\n",
    "\n",
    "data_df=data_df.pipe(drop_aberrant_servings);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1RQok5kHV4R"
   },
   "source": [
    "### 5.3.1 sodium_100g > salt_100g / 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "son6YgZ7WCUe",
    "outputId": "675c8955-0209-4ca4-8dd5-4f9713506189"
   },
   "outputs": [],
   "source": [
    "def plot_salt_sodium(df):\n",
    "    if len(cols_in_df(data_df,['salt_100g','sodium_100g'])) == 2:\n",
    "        sns.regplot(data=df,x='salt_100g',y='sodium_100g',scatter_kws={'s':1}, fit_reg=False)\n",
    "        to_png('5.3.1_plot_salt_sodium_regplot')\n",
    "        #sns.scatterplot(data=df,x='salt_100g',y='sodium_100g',size=1)\n",
    "\n",
    "data_df.pipe(plot_salt_sodium);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1HObKpPHSeX",
    "outputId": "b22b2e81-e877-407e-fddb-de20c2017e4f"
   },
   "outputs": [],
   "source": [
    "def drop_aberrant_sodium_100g(df):\n",
    "    \"\"\"le sodium_100g doit être salt/2.5\n",
    "    Il se peut que le sodium_100g et salt_100g sont simplement invertis\n",
    "    Si c'est le cas, cette procédure supprime le registre car c'est abérrant\n",
    "    \"\"\"\n",
    "    if ('sodium_100g' in df.columns) and ('salt_100g' in df.columns): \n",
    "        filtre = df['sodium_100g']>df['salt_100g']/2.4 \n",
    "        nb_rows= filtre.sum()\n",
    "        print(f'drop_aberrant_sodium_100g, nb registres aberrants : {nb_rows}')\n",
    "        return df[~filtre]\n",
    "    else: return df\n",
    "\n",
    "data_df=data_df.pipe(drop_aberrant_sodium_100g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "qmpQuogWgmEm"
   },
   "source": [
    "## 5.4 energy_100g > 3800 kJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rp67MCvgmEm",
    "outputId": "ee814eb6-fae7-480d-d977-d94b3fa210da"
   },
   "outputs": [],
   "source": [
    "def drop_aberrant_energy(df):\n",
    "    if not ('energy_100g' in df.columns): \n",
    "        return df\n",
    "    filtre = df['energy_100g']>3800\n",
    "    nb_rows= filtre.sum()\n",
    "    print(f'drop_aberrant_energy, nb registres aberrants : {nb_rows}')\n",
    "    return df[~filtre]\n",
    "\n",
    "data_df=data_df.pipe(drop_aberrant_energy);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTdOAO7lD2dJ"
   },
   "source": [
    "### 5.4.1 energy_kcal_100g > energy_100g / 4.184\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "16Nzvlm4WI9g",
    "outputId": "41174df0-a4bb-4ba3-c171-e0708ad0035d"
   },
   "outputs": [],
   "source": [
    "def plot_energy_kcal(df):\n",
    "    if len(cols_in_df(data_df,['energy_100g','energy-kcal_100g'])) == 2:\n",
    "        sns.regplot(data=df,x='energy_100g',y='energy-kcal_100g',scatter_kws={'s':1}, fit_reg=False)\n",
    "        \n",
    "        \n",
    "data_df.pipe(plot_energy_kcal)\n",
    "to_png('5.4.1_plot_energy_kcal_regplot_avant_nettoyage')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "sUl0isGzD0HH",
    "outputId": "5cefe6a4-330c-4f4e-e2d5-93eb5dc0c536"
   },
   "outputs": [],
   "source": [
    "def drop_aberrant_energy_kcal(df):\n",
    "    \"\"\"l'énergie en kcal ne doit pas être plus que l'énergie en kJ\n",
    "    Il se peut que l'energie en kJ et énergie en kcal sont simplement invertis\n",
    "    Si c'est le cas, cette procédure supprime le registre car c'est abérrant\n",
    "    \"\"\"\n",
    "    if ('energy-kcal_100g' in df.columns) and ('energy_100g' in df.columns): \n",
    "        filtre = df['energy-kcal_100g']>df['energy_100g']/4.1\n",
    "        nb_rows= filtre.sum()\n",
    "        print(f'drop_aberrant_energy_kcal[1], nb registres aberrants : {nb_rows}')\n",
    "        if 'energy-kj_100g' in df.columns: \n",
    "            filtre2 = df['energy-kcal_100g']>df['energy-kj_100g']/4.1\n",
    "            nb_rows= filtre2.sum()\n",
    "            print(f'drop_aberrant_energy_kcal[2], nb registres aberrants : {nb_rows}')\n",
    "            filtre = filtre | filtre2\n",
    "        return df[~filtre]\n",
    "    else: return df\n",
    "\n",
    "data_df=data_df.pipe(drop_aberrant_energy_kcal)\n",
    "data_df.pipe(plot_energy_kcal)\n",
    "to_png('5.4.1_plot_energy_kcal_regplot_apres_nettoyage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av7dh_VicMNj",
    "outputId": "ac426b09-7c46-472e-a99c-d5f74aad1ecc"
   },
   "outputs": [],
   "source": [
    "def plot_energy_kj_kcal(df):\n",
    "    if len(cols_in_df(data_df,['energy-kj_100g','energy-kcal_100g'])) == 2:\n",
    "        sns.regplot(data=df,x='energy-kj_100g',y='energy-kcal_100g',scatter_kws={'s':1}, fit_reg=False)\n",
    "        to_png('5.4.1_plot_energy_kj_kcal_regplot')\n",
    "    else:\n",
    "        print(\"'energy-kj_100g' pas dans dataframe\")\n",
    "        \n",
    "        \n",
    "data_df.pipe(plot_energy_kj_kcal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ZKHtajnEgmEm"
   },
   "source": [
    "## 5.5 Whitespace\n",
    "\n",
    "On peut aussi (si besoin) appliquer majuscule, minuscule, enlève les accents, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUdrHFW0k24t",
    "outputId": "35098f21-f8c1-44c8-b2f5-2f33ba530a4e"
   },
   "outputs": [],
   "source": [
    "print(data_df['product_name'].nunique())\n",
    "print(data_df['product_name'].str.strip().nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsszO-6kgmEm",
    "outputId": "a24eb0ef-7fa4-4dff-a60a-a3a74e063214"
   },
   "outputs": [],
   "source": [
    "def trim_whitespace(df,col='labels'):\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "        print(f'trim_whitespace [{col}]')    \n",
    "    return df\n",
    "\n",
    "data_df=data_df.pipe(trim_whitespace,col='labels_en');\n",
    "data_df=data_df.pipe(trim_whitespace,col='product_name');\n",
    "# colonnes ou le whitespace change les nombre de valeurs uniques\n",
    "# product_name\t0.0%\n",
    "# generic_name\t0.2%\n",
    "# quantity\t0.6%\n",
    "# brands\t0.2%\n",
    "# categories\t0.0%\n",
    "# labels\t7.5%\n",
    "# ingredients_text\t0.0%\n",
    "# serving_size\t0.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xegffAhogmEn"
   },
   "source": [
    "## 5.6 Pipeline pour traiter les valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxELHDz9gmEn",
    "outputId": "c96bcd97-286e-48c7-b0b7-5b8de096e7c8"
   },
   "outputs": [],
   "source": [
    "def pipeline_traiter_valeurs_aberrantes(df):\n",
    "    print(f'pipeline_traiter_valeurs_aberrantes, start_time={datetime.now().time():%H:%M:%S}')\n",
    "\n",
    "    return (df\n",
    "            .pipe(drop_non_foods,col='main_category_en')\n",
    "            .pipe(drop_non_foods,col='product_name')\n",
    "            .pipe(drop_aberrant_valeurs_nutritionnelles)\n",
    "            .pipe(drop_aberrant_servings)\n",
    "            .pipe(drop_aberrant_sodium_100g)\n",
    "            .pipe(drop_aberrant_energy)\n",
    "            .pipe(drop_aberrant_energy_kcal)\n",
    "            .pipe(trim_whitespace)\n",
    "            )\n",
    "\n",
    "data_df=data_df.pipe(pipeline_traiter_valeurs_aberrantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "izbrTiSIgmEn"
   },
   "source": [
    "# 6. Etude des valeurs atypiques\n",
    "Les valeurs atypiques sont des outliers, par exemple :\n",
    "- aucune valeur nutritionnelle \n",
    "- beaucoup d'additifs (ex M&Ms)\n",
    "- beaucoup de sel (paquet de sel)\n",
    "- beaucoup de sucre (paquet de sucre)\n",
    "- beaucoup de gras (bouteille d'huile d'olive)\n",
    "- score très haut ou très bas\n",
    "- date très ancien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CywdZjo0gmEn"
   },
   "source": [
    "## 6.1 Produits avec zero valeur nutritionnelle\n",
    "Par exemple : bouteille d'eau, boissons zero calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "7hzcW2WdgmEn",
    "outputId": "fb462197-17a7-467f-a79f-e3f5bbdda667"
   },
   "outputs": [],
   "source": [
    "def get_zero_valeur_nutritionnelle(df:pd.DataFrame):\n",
    "    servings = cols_in_df(df,['fat_100g','sugars_100g','fiber_100g','proteins_100g','salt_100g'])\n",
    "    filtre_ignore_incomplete= df[servings].notnull().all(1) \n",
    "    filtre_total_is_zero =  df[servings].sum(axis=1) <= 0 \n",
    "    filtre= filtre_ignore_incomplete & filtre_total_is_zero\n",
    "    nb_rows= filtre.sum()\n",
    "    print(f'get_zero_valeur_nutritionnelle, nb registres ou total(servings)=0 : {nb_rows}')\n",
    "    zero_val_nutr=df[filtre]\n",
    "    print(zero_val_nutr['pnns_groups_2'].value_counts().head(4))\n",
    "    return zero_val_nutr\n",
    "     \n",
    "\n",
    "data_df.pipe(get_zero_valeur_nutritionnelle)[['product_name','pnns_groups_2']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "-CIzC8MngmEn"
   },
   "source": [
    "## 6.2 Variables numériques : Identification des outliers via box_plots\n",
    "Les box plots montre visuellement 5 des valeurs fourni par dataframe.describe\n",
    "\n",
    "Le box indique ou la moitié des observations tombe (IQR = Inter Quartile Range = Q1 à Q3)\n",
    "\n",
    "- Q3 = 75th percentile (max valeur de la boite)\n",
    "- Q2 = 50th percentile (médiane ligne au 'milieu' de la boite)\n",
    "- Q1 = 25th percentile (min valeur de la boite)\n",
    "\n",
    "Les lignes (whisker) represent 1.5 * (Q2-Q1) en bas ; 1.5 * (Q3-Q2) en haut\n",
    "\n",
    "Valeurs hors de ces lignes sont considérés des 'outliers'\n",
    "\n",
    "Les outliers peut avoir trop d'influence sur l'analyse :\n",
    "- les statistiques\n",
    "- les correlations\n",
    "- les imputations\n",
    "\n",
    "Donc, il faut les supprimer ou ignorer dans certaines analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "6bCmAmvsgmEo",
    "outputId": "fc4afeaa-c6e9-455d-f26b-3868c036de7a"
   },
   "outputs": [],
   "source": [
    "def plot_colonnes_as_box(df:pd.DataFrame):\n",
    "    # mean and median in centre if normal\n",
    "    numeric_cols=df.select_dtypes('number').columns.tolist()\n",
    "    print(f'numeric_cols : {numeric_cols}')\n",
    "    n_rows= 2\n",
    "    n_cols=(len(numeric_cols)+1) // n_rows\n",
    "    if (len(numeric_cols) % n_cols) > 0: n_rows+=1\n",
    "    colors= sns.color_palette(\"tab20\").as_hex()[:len(numeric_cols)+1]\n",
    "    if len(colors)< len(numeric_cols):\n",
    "        colors = colors + colors # max 40 colonnes\n",
    "    _, ax = plt.subplots(figsize=(20,10), ncols=n_cols, nrows= n_rows)\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        sns.boxplot(y=df[col], ax=plt.subplot(n_rows, n_cols, i+1), color=colors[i])\n",
    "        sns.despine()\n",
    "    # espace entre les plots\n",
    "    plt.subplots_adjust(wspace=1, hspace=0.2)\n",
    "    to_png(f'6.2_identification_outliers_par_boxplot')\n",
    "\n",
    "data_df.pipe(plot_colonnes_as_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wFTIwnsZgmEo"
   },
   "source": [
    "## 6.3 Variables numériques : distributions (Histograms)\n",
    "Pas besoin de calculer les bins pour toutes les données, un échantillon nous donne une bonne representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "-nxvuIzYgmEo",
    "outputId": "ca4fdcaa-7646-42e6-fd23-5449f470aace"
   },
   "outputs": [],
   "source": [
    "def plot_colonnes_as_histogram(df):\n",
    "    numeric_cols=df.select_dtypes('number').columns.tolist()\n",
    "    print(f'numeric_cols : {numeric_cols}')\n",
    "    n_cols=4\n",
    "    n_rows=len(numeric_cols) // n_cols \n",
    "    if (len(numeric_cols) % n_cols) > 0: n_rows+=1\n",
    "    colors= sns.color_palette(\"tab20\").as_hex()[:len(numeric_cols)]\n",
    "    if len(colors)< len(numeric_cols):\n",
    "        colors = colors + colors # max 40 colonnes\n",
    "    _, ax = plt.subplots(figsize=(20,20), ncols=n_cols, nrows= n_rows)\n",
    "    sample_size=min(1000,len(df))\n",
    "    dfs=df[numeric_cols].sample(sample_size)\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        ax=sns.histplot(dfs[col].dropna().astype(float), ax=plt.subplot(n_rows, n_cols, i+1), \n",
    "        bins=20, kde=True, stat='proportion',color=colors[i])\n",
    "        ax.set_xlabel(col)\n",
    "        sns.despine()\n",
    "\n",
    "    # espace entre les plots\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    to_png(f'6.3_distribution_colonnes_numeriques_histogram')\n",
    "\n",
    "data_df.pipe(plot_colonnes_as_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "6TTz18uagmEo"
   },
   "source": [
    "## 6.4 Variables numériques : description avec skew et kurtosis\n",
    "On peut résumer les distributions avec mean, var, skew et kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "4i1xxtwtgmEo",
    "outputId": "81ed57e6-5433-494b-b464-c07fa57dcee0"
   },
   "outputs": [],
   "source": [
    "def decrire_distribution(df:pd.DataFrame):\n",
    "    stats = df.describe(include=[np.number],datetime_is_numeric=True)\n",
    "    cols=stats.columns.tolist()\n",
    "    # stats.loc['var'] = df[cols].var().tolist()\n",
    "    stats.loc['skew'] = df[cols].skew().tolist()\n",
    "    stats.loc['kurt'] = df[cols].kurtosis().tolist()\n",
    "    return stats\n",
    "\n",
    "stats=data_df.pipe(decrire_distribution)\n",
    "print(len(stats.columns.tolist()))\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "IXXZLZnYgmEo"
   },
   "source": [
    "## 6.5 Variables catégoriques : description\n",
    "Pour analyser les catégories, il faut savoir :\n",
    "- le nombre de valeurs uniques\n",
    "- la longueur des colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "C6Vp5LbNgmEo",
    "outputId": "35303db7-2038-450a-e6f0-aa2881d8410a"
   },
   "outputs": [],
   "source": [
    "def count_unique(df: pd.DataFrame):\n",
    "    uniq_df = pd.DataFrame(columns=['column', 'unique'])\n",
    "    categs= df.select_dtypes('category').columns.to_list()\n",
    "    for col in categs:\n",
    "        uniq_df = uniq_df.append({'column': col, 'unique': len(df[col].cat.categories)}, ignore_index=True)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # uniq= df[col].str.split(',', expand=True).stack().unique().tolist()\n",
    "            # uniq = explode_series(df[col]).nunique()\n",
    "            uniq = explode_series(pd.Series(df[col].unique())).nunique()\n",
    "            uniq_df = uniq_df.append({'column': col, 'unique': uniq}, ignore_index=True)\n",
    "    uniq_df = uniq_df.set_index('column')\n",
    "    return uniq_df\n",
    "\n",
    "# count_unique(data_df[['additives_en']])\n",
    "count_unique(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "DTSkuAHrgmEo",
    "outputId": "28127581-dddc-42c7-c948-31be0247fb9f"
   },
   "outputs": [],
   "source": [
    "def max_len_colonnes(df: pd.DataFrame, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Retourne (un estimé du) largeur maximum des colonnes text d'un dataframe \n",
    "    - aide à valider l'uniformité des clés et autres données\n",
    "    \"\"\"\n",
    "    if len(df) > sample_size :\n",
    "        df=df.sample(sample_size)\n",
    "    mesurer = np.vectorize(len)\n",
    "    max_df = pd.DataFrame(columns=['column', 'max_len'])\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            uniq = df[col].dropna().explode().unique()\n",
    "            # print(f'max_len_colonnes, nb uniq = {len(uniq)}')\n",
    "            if len(uniq) > 1000:\n",
    "                uniq = uniq[:1000]\n",
    "            # print(f'max_len_colonnes, cut nb uniq = {len(uniq)}')\n",
    "            max_len = mesurer(uniq.astype(str)).max(axis=0)\n",
    "            max_df = max_df.append(\n",
    "                {'column': col, 'max_len': max_len}, ignore_index=True)\n",
    "    max_df = max_df.set_index('column')\n",
    "    return max_df\n",
    "\n",
    "max_len_colonnes(data_df[['additives_en']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "hLCQ4jBSgmEp",
    "outputId": "b537801d-2b36-4aa3-8a5e-43f887b6e639"
   },
   "outputs": [],
   "source": [
    "def decrire_dataframe(df: pd.DataFrame,calc_max_len=False):\n",
    "    \"\"\"\n",
    "    Retourner un dataframe avec des informations sur les colonnes d'un dataframe\n",
    "    \"\"\"\n",
    "    ret = df.columns.to_frame(name=\"column\").set_index('column')\n",
    "    ret['count'] = df.notnull().sum()\n",
    "    # ret['unique'] = df.nunique() # ne marche pas avec des colonnes tag\n",
    "    ret['unique'] = count_unique(df)\n",
    "    ret['dtype'] = df.dtypes\n",
    "    if calc_max_len:\n",
    "        ret['max_length'] = max_len_colonnes(df)\n",
    "    return ret.reset_index()\n",
    "\n",
    "decrire_dataframe(data_df[['additives_en']], calc_max_len=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "cA02a7nQgmEp",
    "outputId": "a89233e0-d514-487b-86d3-a579d69a2c9e"
   },
   "outputs": [],
   "source": [
    "\n",
    "def decrire_colonnes_object(df: pd.DataFrame,calc_max_len=False):\n",
    "    \"\"\"\n",
    "    Retourner un dataframe avec des informations sur les colonnes objet d'un dataframe\n",
    "    \"\"\"\n",
    "    obj_cols=df.select_dtypes(['object','category']).columns\n",
    "    ret = obj_cols.to_frame(name=\"column\").set_index('column')\n",
    "    ret['count'] = df.notnull().sum()\n",
    "    # ret['unique'] = df.nunique() # ne marche pas avec des colonnes tag\n",
    "    ret['unique'] = count_unique(df)\n",
    "    ret['dtype'] = df.dtypes\n",
    "    for col in list(obj_cols):\n",
    "        if (str(df[col].dtype) =='category'):\n",
    "            ret.loc[col,'dtype']='category'\n",
    "        #elif df[col].str.contains(',').any(): \n",
    "        #    ret.loc[col,'dtype']='list'\n",
    "        else:\n",
    "            ret.loc[col,'dtype']='str'\n",
    "    if calc_max_len:\n",
    "        ret['max_length'] = max_len_colonnes(df)\n",
    "    return ret.reset_index()\n",
    "\n",
    "decrire_colonnes_object(data_df[['pnns_groups_1']], calc_max_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxBpc31bgmEp",
    "outputId": "78b51dac-5ae9-46a7-f95f-a1dd7f60dba9"
   },
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 801
    },
    "id": "hd1aJFEEgmEp",
    "outputId": "884249e0-ad8a-472f-e428-3e74c1a0f5e0"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "data_df.pipe(decrire_colonnes_object, calc_max_len=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uxm_uhMHgmEp"
   },
   "outputs": [],
   "source": [
    "# data_dict.to_csv(os_path_join(OUT_FOLDER, RAW_DATA_DICT), encoding='UTF-8',index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "MpFmp0P7gmEp"
   },
   "source": [
    "# 7. Imputation de valeurs manquantes\n",
    "Maintenant qu'on a compris la distribution des colonnes numériques et traité les outliers,\n",
    "on peut imputer les valeurs manquantes\n",
    "\n",
    "- Avec la fonction `.describe()` pour voir les min/max ou en faisant des boxplot pour visualiser la distribution, tu devrais y voir plus clair.\n",
    "- En regardant les règles de (data quality)[https://github.com/openfoodfacts/openfoodfacts-server/blob/main/taxonomies/data_quality.result.txt]\n",
    "  de OpenFoodFacts\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dizGh268gmEp"
   },
   "source": [
    "## 7.1 Objectifs : \n",
    "\n",
    "Notre application se base sur les produits dont on connait les additifs :\n",
    "1. remplir les valeurs nutriscore manquantes\n",
    "2. imputer les valeurs nutritionnelles manquantes\n",
    "3. remplir le main_category manquantes\n",
    "\n",
    "### 7.1.1 Ordre de remplissage des valeurs manquantes\n",
    "- On trie par taux de remplissage, pour déterminer l'ordre de rémplissage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "L_5Nwg2igmEq",
    "outputId": "a5a9ac18-14f3-4c85-c0eb-b8a773209065"
   },
   "outputs": [],
   "source": [
    "def sort_columns_by_remplissage(df):\n",
    "    return df.isnull().mean().sort_values().index.to_list()\n",
    "\n",
    "def plot_ordre_remplissage_valeurs_manquantes(df):    \n",
    "    data_to_explore=df.dropna(subset=['additives_n'])\n",
    "    anal_cols= cols_in_df(data_to_explore,analyse_cols)\n",
    "    cols= sort_columns_by_remplissage(data_to_explore[anal_cols])\n",
    "    data_to_explore.pipe(plot_missing_matrix, cols=cols)\n",
    "    to_png(f'7.1.1_ordre_de_remplissage_valeurs_manquantes')\n",
    "\n",
    "data_df.pipe(plot_ordre_remplissage_valeurs_manquantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMRiJlnbgmEq"
   },
   "source": [
    "### Ordre d'imputation des valeurs manquantes\n",
    "\n",
    "La stratégie de remplissage des valeurs manquantes est:\n",
    "1. Remplir les valeurs nutritionnelles manquantes\n",
    "1. remplir les valeurs nutriscore manquantes par \n",
    "2. imputer les valeurs nutritionnelles manquantes\n",
    "3. remplir le main_category manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "G6bmN3gKgmEq"
   },
   "source": [
    "## 7.2 Tests de normalité des distributions\n",
    "Pour pouvoir choisir une stratégie de remplissage des valeurs manquantes,\n",
    "il faut determiner si les variables sont distribuées normalement\n",
    "\n",
    "- histogram / kde (ci-dessus, comparer avec distribution normal)\n",
    "- box plot (ci-dessus, moyenne et médiane au centre si la distribution est normal)\n",
    "- describe() (ci-dessus, skew=0 et kurtosis=0 si normal)\n",
    "- QQ plot (ligne et droite si la distribution normale)\n",
    "- tests:\n",
    "        - Kolmogorov-smirnov, très susceptible aux outliers\n",
    "        - Shapiro Wilk \n",
    "\n",
    "Référence :\n",
    "- https://towardsdatascience.com/6-ways-to-test-for-a-normal-distribution-which-one-to-use-9dcf47d8fa93\n",
    "- https://towardsdatascience.com/normality-tests-in-python-31e04aa4f411\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CVVMRLVgmEq"
   },
   "source": [
    "### 7.2.2 Tests de normalité - distribution plots (histograms / kde), boxplots, quantile-quantile plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "-uwFxZBOgmEq",
    "outputId": "f564a131-bc94-493b-ccc1-a9c09d378fff"
   },
   "outputs": [],
   "source": [
    "# Quantile Quantile Plot\n",
    "# Ordered values versus theoretical quantiles\n",
    "import statsmodels.api as sm\n",
    "import pandas.util.testing as tm\n",
    "# from scipy.stats import norm\n",
    "\n",
    "def plot_qq(df,series='nutriscore_score',titre='Quantile-Quantile Plot'):\n",
    "    sm.qqplot(df[series].dropna(), line='45',fit=True)\n",
    "    plt.title(titre)\n",
    "    plt.suptitle(series)\n",
    "\n",
    "plot_qq(data_df,series='nutriscore_score')\n",
    "to_png(f'7.2.1_test_normalite_qq_plot_nutriscore_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "apMUe8s_gmEq",
    "outputId": "4348fa7c-0434-42ad-bd0e-f3da01292eed"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# generate a normal distrib\n",
    "def plot_qq2(df,series):\n",
    "    stats.probplot(df[series].dropna(), dist='norm', fit=True,plot=plt)\n",
    "    # x = stats.norm.rvs(loc=0, scale=1, size=1000)\n",
    "    # stats.probplot(x, dist='norm', plot=plt)\n",
    "\n",
    "plot_qq2(data_df,'nutriscore_score')\n",
    "to_png(f'7.2.1_test_normalite_qq2_plot_nutriscore_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5_0nKQygmEq"
   },
   "source": [
    "### 7.2.2 Tests de normalité - statistiques et p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82t4cQn-gmEr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_stat_p(testname,stat,p):\n",
    "    print (f'{testname}: stat={stat:.3f}, p={p:.3f}')\n",
    "    # reject H0 if p<=0.05\n",
    "    if p> 0.05:\n",
    "        print('probably Gaussian')\n",
    "    else:\n",
    "        print('probably not Gaussian')\n",
    "\n",
    "def format_stat_p(stat, p):\n",
    "    ch= f'stat={stat:.3f}, p={p:.3f} '\n",
    "    if p<0.001: ch +='***'\n",
    "    elif p<0.01: ch +='**'\n",
    "    elif p<0.05: ch +='*'\n",
    "    return ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ez5RWmsBgmEr"
   },
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test (1965)\n",
    "from scipy.stats import norm,shapiro\n",
    "\n",
    "def test_shapiro(series):\n",
    "    my_data = norm.rvs(size=500)\n",
    "    stat, p = shapiro(series)\n",
    "    # print_stat_p('Shapiro-Wilk', stat,p)\n",
    "    return format_stat_p(stat,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b91zRiXigmEr"
   },
   "outputs": [],
   "source": [
    "#D’Agostino’s K-squared test\n",
    "# D’Agostino’s K-squared test check’s normality of a variable based on skew (symmetry) and kurtosis.\n",
    "from scipy.stats import normaltest\n",
    "def test_k_squared(series):\n",
    "    (stat,p)=normaltest(series)\n",
    "    # print_stat_p('D’Agostino’s K-squared',stat,p)\n",
    "    return format_stat_p(stat,p)\n",
    "\n",
    "# Jarque-Bera (based on Skew and kurtosis, n > 2000)\n",
    "from scipy.stats import jarque_bera\n",
    "def test_jarque_bera(series):\n",
    "    stat,p=jarque_bera(series)\n",
    "    # print_stat_p('Jarque-Bera',stat,p)\n",
    "    return format_stat_p(stat,p)\n",
    "\n",
    "\n",
    "#Chi-square test for normality\n",
    "from scipy.stats import chisquare\n",
    "def test_chi_square(series):\n",
    "    stat,p=chisquare(series)\n",
    "    # print_stat_p('Chi-square',stat,p)\n",
    "    return format_stat_p(stat,p)\n",
    "\n",
    "#lilliefors\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "def test_lilliefors(series):\n",
    "    stat,p=lilliefors(series)\n",
    "    # print_stat_p('Lilliefors',stat,p)\n",
    "    return format_stat_p(stat,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcwFJeq7gmEr"
   },
   "outputs": [],
   "source": [
    "# Kolmogorov-Smirnov goodness of fit test\n",
    "# tests the distribution F(x) of an observed random variable against the normal distribution\n",
    "from scipy.stats import kstest\n",
    "def test_kolmogorov_smirnov(series):\n",
    "    stat, p = kstest(series, 'norm')\n",
    "    # print_stat_p('Kolmogorov-Smirnov',stat,p)\n",
    "    return format_stat_p(stat,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "f5_H7vYsgmEr",
    "outputId": "5662f90d-c3a5-4a12-f75c-ab0455055ea9"
   },
   "outputs": [],
   "source": [
    "def test_normality(df):\n",
    "    stats= decrire_distribution(df)\n",
    "    cols=stats.columns.tolist()\n",
    "    for col in cols:\n",
    "        series=df[col].dropna()\n",
    "        sample_size=min(4000,len(series))\n",
    "        vals=series.sample(sample_size)\n",
    "        stats.loc['K-squared',col]=test_k_squared(vals)\n",
    "        stats.loc['Shapiro',col]=test_shapiro(vals)\n",
    "        stats.loc['Chi-square',col]=test_chi_square(vals)\n",
    "        # stats.loc[col,'Kolmogorov_Smirnov']=test_kolmogorov_smirnov(vals)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "data_df.pipe(test_normality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM_-BjOHgmEr"
   },
   "source": [
    "On voit qu'aucun des colonnes numériques a une distribution normale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nYh-9mysgmEr"
   },
   "source": [
    "## 7.3 Evaluation des techniques d'imputation de valeurs manquantes \n",
    "- <https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-py>\n",
    "-<https://towardsdatascience.com/preprocessing-regression-imputation-of-missing-continuous-values-f612179bafb4>\n",
    "\n",
    "### 7.3.1 Techniques d'imputation différentes :\n",
    "\n",
    "- SimpleImputer : imputation avec une valeur constante (0)\n",
    "- SimpleImputer : imputation avec la moyenne\n",
    "- KNNImputer    : imputation avec k nearest neighbor\n",
    "- IterativeImputer: imputation iterative (MICE)\n",
    "\n",
    "\n",
    "L'imputation iterative fait plusieurs iterations, exige encodage des variables catégoriques et peut prend beaucoup de temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7TdvwEQgmEs"
   },
   "source": [
    "#### Étapes pour évaluer la performance d'une méthode d'imputation\n",
    "1. Choisir des colonnes X pour imputer la variable y\n",
    "2. Créer un jeu de données sans valeurs manquantes `[X,y].dropna()`\n",
    "3. Diviser en jeux de données `train` et `test`\n",
    "4. entrainer le model sur des données `train`\n",
    "5. tester la performance du model sur de données `test`, pas connu du model\n",
    "\n",
    "Basé sur les résultats, choisir la meilleure méthode d'imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "YZl4lK2OgmEs"
   },
   "source": [
    "### 7.3.2 Création de jeu de données X(features) et y(target)\n",
    "\n",
    "On crée un jeu de données complet pour entrainer le model et tester sont performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-nDvMVTgmEs",
    "outputId": "d0a62bce-9b6d-41d6-a50f-e832c3e0281a"
   },
   "outputs": [],
   "source": [
    "def get_jeu_x_y(df, x_vars=[], y_vars=['nutriscore_score'], sample_size=10000, dropna=True):\n",
    "    \"\"\"Créer un jeu de données pour entrainer et évaluar plusieurs classifiers\n",
    "    - Pas besoin de toute les registres \n",
    "    \"\"\"\n",
    "    if x_vars is None or len(x_vars) ==0:\n",
    "        x_vars= get_colonnes_nutritionnelles_100g(df)\n",
    "    x_vars=cols_in_df(df,x_vars)    \n",
    "#    x_vars=['energy_100g','sugars_100g','saturated-fat_100g','sodium_100g','fat_100g','proteins_100g','fiber_100g','carbohydrates_100g']\n",
    "    y_vars=cols_in_df(df,y_vars)  \n",
    "    ret=df[x_vars + y_vars].dropna() if dropna else df[x_vars + y_vars].dropna(subset=x_vars,how='all')\n",
    "    sample_size=min(len(ret), sample_size)\n",
    "    ret=ret.sample(sample_size)\n",
    "    return ret[x_vars], ret[y_vars]\n",
    "\n",
    "# Pour entrainement et comparaison d'estimateurs, pas besoin de toutes les registres\n",
    "# On limite la taille\n",
    "SAMPLE_SIZE=10000\n",
    "x_vars= get_colonnes_nutritionnelles_100g(data_df)\n",
    "X, y = get_jeu_x_y(data_df, sample_size=SAMPLE_SIZE)\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egA7u8u_gmEs"
   },
   "source": [
    "On note que seulement 20% des données sont complétement remplis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "XTHwekCPgmEs"
   },
   "source": [
    "### 7.3.2 Étape 1 : Création des jeux de données train et test\n",
    "\n",
    "Division des données X et y en jeu d'entrainement du model ('train') et jeu d'évaluation du model ('test')\n",
    "\n",
    "Pour comparer la performance des différentes imputations, on entraîne chaque model sur le jeu de données train et puis fait un evaluation de performance sur un jeu de données test.\n",
    "- `random_state` permet de reproduire les résultats identiques à chaque run de ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWj5xI4PgmEs",
    "outputId": "94331cef-6e1f-44fb-fd9c-26211885420e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,y.to_numpy().ravel(),test_size=0.2,random_state=2)\n",
    "\n",
    "print(f'x_train: {x_train.shape}; y_train: {y_train.shape}')\n",
    "print(f'x_test: {x_test.shape}; y_test: {y_test.shape}')\n",
    "\n",
    "# data={'x_train':x_train,'x_test':x_test,'y_train':y_train,'y_test':y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCdZU6WMgmEs"
   },
   "source": [
    "### 7.3.3 Model 1 : régression linéaire sur les variables X, sans normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WapDZutAgmEs",
    "outputId": "ebd65f8b-982c-4a6d-9fe2-52adc2836d5b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entraine sur le jeu de données 'train'\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# Evaluation de précision de nutriscore_score\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwTeIZnogmEt"
   },
   "source": [
    "#### Autres mesures de performance\n",
    "- r2_score (défaut): le coefficient de determination R^2 of the prediction.\n",
    "- MAE (mean_absolute_error)\n",
    "- MSE (mean_square_error)\n",
    "- RMSE (root_mean_square_error).\n",
    "\n",
    "Nutriscore_score est discrete -> on peut aussi considéré un problème de classification\n",
    "- accuracy_score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKSsh7sxgmEt",
    "outputId": "2a34885b-5c91-48ef-ff77-02c923b120d8"
   },
   "outputs": [],
   "source": [
    "# Prédire sur le jeu de données 'test'\n",
    "y_pred = model.predict(x_test).round()\n",
    "\n",
    "from sklearn import metrics\n",
    "print(f'R2={metrics.r2_score(y_test,y_pred)}')\n",
    "print(f'MAE={metrics.mean_absolute_error(y_test,y_pred)}')\n",
    "print(f'MSE={metrics.mean_squared_error(y_test,y_pred)}')\n",
    "print(f'Accuracy={metrics.accuracy_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "0rH9UafXgmEt",
    "outputId": "62c3b86f-f5ed-4ab8-a4a5-9de00c1e3008"
   },
   "outputs": [],
   "source": [
    "def plot_predict_vs_actual(y_test=[1,2,3],y_pred=[1,2,3], hue=None,titre=''):\n",
    "    fig,axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    ax=plt.subplot(1,2,1)\n",
    "    sns.scatterplot(x=y_test,y=y_pred,hue=hue,legend=None, ax=ax)\n",
    "    if not (isinstance(y_test[0], str)):\n",
    "        r2=metrics.r2_score(y_test,y_pred)\n",
    "        ax.annotate(f'R2 = {r2:.3f}',xy=(-15,20))\n",
    "    # plt.text(f'R2 = {r2:.3f}',xy=(0,0.9))\n",
    "    ax.set_xlabel('actual nutriscore_score')\n",
    "    ax.set_ylabel('predicted nutriscore_score')\n",
    "    ax.set_title('Prévision du nutriscore_score')\n",
    "    if not hue is None:\n",
    "        plt.legend(labels=hue)\n",
    "    plt.suptitle(titre)\n",
    "    ax=ax=plt.subplot(1,2,2)\n",
    "    # Plot the original distribution\n",
    "    sns.kdeplot(y_test, label='Original Distribution', ax=ax)\n",
    "    sns.kdeplot(y_pred, label='Predicted Distribution',ax=ax)\n",
    "    plt.legend(labels=['original', 'predicted'])\n",
    "    ax.set_xlabel('nutriscore_score')\n",
    "    # ax.set_ylabel('')\n",
    "    ax.set_title('Distribution du nutriscore_score')\n",
    "\n",
    "plot_predict_vs_actual(y_test,y_pred, titre='Régression linéaire')\n",
    "to_png('7.3.3_imputation_nutriscore_par_regression_lineaire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aoB635tgmEt"
   },
   "source": [
    "On voit que l'imputation par régression linéaire n'est pas adaptée pour le nutriscore, car\n",
    "- la distribution n'est pas normal,\n",
    "- la regression linéaire des valeurs manquantes change beaucoup la distribution\n",
    "- il est très susceptible à des outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wof_KQRrgmEt"
   },
   "source": [
    "### 7.3.4 Model 2 : KNeighbors estimation de Nutriscore, sans normalisation\n",
    "\n",
    "- <https://www.ritchieng.com/machine-learning-k-nearest-neighbors-knn/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "jb4fcdfUgmEt",
    "outputId": "43b488ad-f6cc-4809-c871-33ce531deb48"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def plot_knn_estimates(k_val=1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "    knn.fit(x_train, y_train)\n",
    "    print(f'KNN score={knn.score(x_test,y_test)}')\n",
    "\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    print(f'Accuracy={metrics.accuracy_score(y_test,y_pred)}')\n",
    "    print(f'R2={metrics.r2_score(y_test,y_pred)}')\n",
    "    print(f'MAE={metrics.mean_absolute_error(y_test,y_pred)}')\n",
    "    print(f'MSE={metrics.mean_squared_error(y_test,y_pred)}')\n",
    "    plot_predict_vs_actual(y_test,y_pred,titre=f'KNN Neigbors, k={k_val}')\n",
    "\n",
    "plot_knn_estimates(k_val=1)\n",
    "to_png('7.3.4_imputation_nutriscore_par_KNN_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdlU6UjCgmEt"
   },
   "source": [
    "### 7.3.5 Model 3 : Essaie avec plusieurs valeurs de k voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFDm2j37gmEu",
    "outputId": "f71c3ae5-f5ab-4017-9193-8512b6859d88"
   },
   "outputs": [],
   "source": [
    "def score_knn_model( x_train, x_test,y_train,y_test,k_max=15):\n",
    "    k_range = range(1, k_max)\n",
    "    scores = {}\n",
    "\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(x_train, y_train)\n",
    "        y_pred = knn.predict(x_test)\n",
    "        scores[k]=metrics.accuracy_score(y_test, y_pred)\n",
    "    return scores\n",
    "    \n",
    "scores=score_knn_model(x_train, x_test,y_train,y_test, k_max=15)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "SOA42fj5gmEu",
    "outputId": "29aaf5f4-da00-4164-9199-8a9c886c3a71"
   },
   "outputs": [],
   "source": [
    "def plot_knn_elbow_curve(k_values,scores):\n",
    "    \"\"\"plot the relationship between K and testing accuracy\"\"\"\n",
    "    ax=sns.lineplot(x=k_values, y=scores)\n",
    "    ax.set_xlabel('Valeur de K pour KNN')\n",
    "    ax.set_ylabel('Test Accuracy Score')\n",
    "\n",
    "plot_knn_elbow_curve(k_values=scores.keys(),scores=scores.values())\n",
    "to_png('7.3.5_imputation_nutriscore_par_KNN_elbow_curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Jv2tt2wgmEu"
   },
   "source": [
    "- Ayant une valeur de K trop petit produit trop de bruit\n",
    "- Si k est trop grand on perd le precision\n",
    "- Meilleure valeur sera d'utiliser une valeur impar au coude du plot ci-dessus\n",
    "\n",
    "Donc, on utilise la valeur k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "0ZrvI8EogmEu",
    "outputId": "f2e0636f-a487-4b69-f64f-08445fc20150"
   },
   "outputs": [],
   "source": [
    "plot_knn_estimates(k_val=3)\n",
    "to_png('7.3.5.1_imputation_nutriscore_par_KNN_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "JlTFKBsegmEu",
    "outputId": "e4b06330-252c-45ff-a3d2-dad61fa948c3"
   },
   "outputs": [],
   "source": [
    "plot_knn_estimates(k_val=5)\n",
    "to_png('7.3.5.2_imputation_nutriscore_par_KNN_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "HQSBx73wgmEu"
   },
   "source": [
    "### 7.3.6 Model 4: Avec normalisation (Standard Scaler) des valeurs nutritionnels (via pipelines)\n",
    "\n",
    "#### 7.3.6.1 Regression linéaire\n",
    "Normalisation des valeurs ne change pas les résultats de régression linéaire - les coefficients de regression font la 'normalisation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Am1O0j8dgmEu",
    "outputId": "24b4637e-60c0-4c53-a386-b8bdb3f59416"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LinearRegression())\n",
    "pipe.fit(x_train, y_train)  # apply scaling on training data\n",
    "score=pipe.score(x_test, y_test)  # apply scaling on testing data, without leaking training data.\n",
    "y_pred=pipe.predict(x_test).round()\n",
    "\n",
    "print(f'score = {score}')\n",
    "if not isinstance(y_test,str):\n",
    "    r2=metrics.r2_score(y_test,y_pred)\n",
    "    accuracy=metrics.accuracy_score(np.round(y_test),np.round(y_pred))\n",
    "    print(f'r2 = {r2}')\n",
    "    print(f'accuracy = {accuracy}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP0ZoFtxgmEu"
   },
   "source": [
    "#### 7.3.6.2 KNN avec standard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "l9JzunvQgmEv",
    "outputId": "a25bbd26-91b5-4f8e-b015-ccdd36c401c5"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "\n",
    "def score_knn_pipeline(x_train, x_test,y_train,y_test,k_max=15):\n",
    "    k_range = range(1, k_max)\n",
    "    scores = {}\n",
    "\n",
    "    for k in k_range:\n",
    "        # knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        model: Pipeline = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=k))\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores[k]=metrics.accuracy_score(y_test, y_pred)\n",
    "    return scores\n",
    "    \n",
    "scores=score_knn_pipeline(x_train, x_test,y_train,y_test,k_max=15)\n",
    "plot_knn_elbow_curve(k_values=scores.keys(),scores=scores.values())\n",
    "to_png('7.3.6.2_imputation_nutriscore_par_KNN_elbow_curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWJ3xlFXgmEv"
   },
   "source": [
    "On voit la prevision (accuracy_score) est améliorée avec scaling\n",
    "\n",
    "On utilise k=3 (le coude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRnrN8qXgmEv"
   },
   "source": [
    "### 7.3.7 Améliorer le score en prenant compte de PNNS_group_1 et 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "id": "ZhZxK9rygmEv",
    "outputId": "9f747c59-bb5d-4597-becc-b1c3c295901c"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "numeric_features = ['energy_100g','sugars_100g','saturated-fat_100g','sodium_100g','fat_100g','proteins_100g','fiber_100g']\n",
    "numeric_features=get_colonnes_nutritionnelles_100g(data_df)\n",
    "#numeric_features=['energy_100g','fat_100g', 'saturated-fat_100g', 'sugars_100g', 'proteins_100g', 'fruits-vegetables-nuts-estimate-from-ingredients_100g']\n",
    "print(numeric_features)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", KNNImputer()),\n",
    "         (\"scaler\", StandardScaler())\n",
    "         ]\n",
    ")\n",
    "\n",
    "categorical_features = ['pnns_groups_1','pnns_groups_2']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define pipeline with an arbitrary number of transformer in a tuple array\n",
    "model = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"clf\", KNeighborsClassifier(n_neighbors = 3))\n",
    "])\n",
    "\n",
    "print(model)\n",
    "print('--------------------------')\n",
    "\n",
    "# sample size = 100000 prend quelques minutes\n",
    "SAMPLE_SIZE=min(10000, len(data_df))\n",
    "\n",
    "x_vars= numeric_features + categorical_features\n",
    "X, y = get_jeu_x_y(data_df, x_vars=x_vars, sample_size=SAMPLE_SIZE)\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,y.to_numpy().ravel(),test_size=0.2,random_state=2)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(f'KNN score = {model.score(x_test,y_test)}')\n",
    "print(f'accuracy score = {metrics.accuracy_score(y_test,y_pred)}')\n",
    "\n",
    "plot_predict_vs_actual(y_test,y_pred,hue=x_test['pnns_groups_1'])\n",
    "to_png('7.3.7 KNN_k_3_avec_pnns_groups_1_et_2')\n",
    "\n",
    "print(f'Misclassified samples: {(y_test != y_pred).mean():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmHkXJam-QxN"
   },
   "source": [
    "L'addition des variables catégoriques pnns_groups_1 et pnns_groups_2 améliore la prévision;\n",
    "\n",
    "On a trés peu de données de `fiber_100g` et FLN(fruit légumes noix) - ce qui peux expliquer pourquoi on a toujours une grande écarte entre des prévisions et le nutriscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ta7ujXDYSOsV"
   },
   "outputs": [],
   "source": [
    "x_train=y_train=x_test=y_test=y_pred=X=y=None\n",
    "#del x_train; del y_train; del x_test; del y_test; del y_pred; del X; del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCqSMttQgmEv"
   },
   "source": [
    "### 7.3.8 Imputation avec des Imputers\n",
    "\n",
    "Le scoring était fait avec des Classifiers\n",
    "\n",
    "L'imputation est faite avec les Imputers\n",
    "KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "6GIHx7PfgmEv",
    "outputId": "4c7b8a62-b0a6-421b-eb4f-d16cacde8b52"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer,KNNImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "numeric_features = get_colonnes_nutritionnelles_100g(data_df)\n",
    "    \n",
    "#numeric_features=['energy_100g','sugars_100g','saturated-fat_100g','sodium_100g','fat_100g','proteins_100g','fiber_100g','carbohydrates_100g']\n",
    "labels='nutriscore_score'\n",
    "\n",
    "def plot_imputer_distributions(df,labels='nutriscore_score',features=numeric_features,show_features=False):\n",
    "    data=df[features + [labels]].dropna(how='all')\n",
    "    sample_size=min(1000,len(data))\n",
    "    data=data.sample(sample_size).copy(deep=True)\n",
    "    nb_rows = len(features)+1 if show_features else 1\n",
    "    _, axs = plt.subplots(nrows=nb_rows, ncols=1 , figsize=(8,4*nb_rows))\n",
    "    axs = axs if show_features else [axs]\n",
    "    # Plot the original distribution\n",
    "    sns.kdeplot(data[labels], label=\"Original Distribution\", ax=axs[0])\n",
    "    if show_features:\n",
    "        for i in range(0,len(features)):\n",
    "            sns.kdeplot(data[features[i]], label=\"Original Distribution\", ax=axs[i+1])\n",
    "    strategies = [\n",
    "       IterativeImputer(estimator=BayesianRidge()),\n",
    "       IterativeImputer(estimator=KNeighborsRegressor()),\n",
    "       IterativeImputer(estimator=ExtraTreesRegressor()),\n",
    "       IterativeImputer(estimator=DecisionTreeRegressor()),\n",
    "    ]\n",
    "    for imputer in strategies:\n",
    "        imputed_data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "        sns.kdeplot(imputed_data[labels], label=imputer.estimator, ax=axs[0])\n",
    "        if show_features:\n",
    "            for i in range(0,len(features)):\n",
    "                sns.kdeplot(imputed_data[features[i]], label=imputer.estimator, ax=axs[i+1])\n",
    "\n",
    "    imputer=KNNImputer(n_neighbors=3)\n",
    "    imputed_data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "    sns.kdeplot(imputed_data[labels], label='KNN Imputer', ax=axs[0])\n",
    "    if show_features:\n",
    "        for i in range(0,len(features)):\n",
    "            sns.kdeplot(imputed_data[features[i]], label='KNN Imputer', ax=axs[i+1])\n",
    "    \n",
    "    axs[0].set_xlim([-20, 50])\n",
    "    for ax in axs:\n",
    "        ax.legend()\n",
    "    if show_features:\n",
    "        plt.gcf().subplots_adjust(hspace=0.5)\n",
    "\n",
    "SAMPLE_SIZE=min(10000, len(data_df))\n",
    "plot_imputer_distributions(data_df.sample(SAMPLE_SIZE))\n",
    "to_png('7.3.8_imputation_distributions_nutriscore')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6pRRTiKgmEv"
   },
   "source": [
    "Les meilleures distributions sont produites par KNNImputer et DecisionTreeRegressor, mais ça a du mal à converger\n",
    "\n",
    "On utilise KNNImputer, car les distributions des colonnes nutritionnelles reste les plus similaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOvrWgRLgmEw"
   },
   "source": [
    "## 7.4 Imputation des valeurs nutritionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQkfEMkdgmEw",
    "outputId": "eea9846d-6763-4b18-ae37-7252eea49cf1"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.impute import KNNImputer\n",
    "numeric_features=['energy_100g','sugars_100g','sodium_100g','saturated-fat_100g','fat_100g','proteins_100g','fiber_100g']\n",
    "labels=['nutriscore_score']\n",
    "features_nutritionnelles = numeric_features + labels\n",
    "\n",
    "def impute_valeurs_nutritionnelles_manquantes(df:pd.DataFrame, \n",
    "                                              features_to_impute=features_nutritionnelles, \n",
    "                                              sample_size=100000):\n",
    "    features_to_impute=cols_in_df(df,features_to_impute)\n",
    "    sample_size= max(len(df[features_to_impute].dropna(how='all')),1000)\n",
    "\n",
    "    data_sample = df[features_to_impute].dropna(how='all').sample(sample_size)\n",
    "    print(f'impute_valeurs_nutritionnelles_manquantes, data_sample.shape = {data_sample.shape}')\n",
    "    # Init the transformer\n",
    "    imputer =  make_pipeline(StandardScaler(), KNNImputer(n_neighbors=3, missing_values=np.nan))\n",
    "    # imputer = KNNImputer(n_neighbors=3, missing_values=np.nan)\n",
    "    # Fit (entraine) sur l'échantillon de registres\n",
    "    print(f'impute_valeurs_nutritionnelles_manquantes, start_fit : {datetime.now().time():%H:%M:%S}')\n",
    "    imputer.fit(data_sample)\n",
    "    print(f'impute_valeurs_nutritionnelles_manquantes,   end_fit : {datetime.now().time():%H:%M:%S}')\n",
    "\n",
    "\n",
    "\n",
    "    # Impute seulement ou il y a des données des additives et la nutriscore et inconnu \n",
    "    filtre= df['additives_n'].notnull() & df['nutriscore_score'].isna()\n",
    "    print(f'nb. nutriscore to impute= {filtre.sum()}')\n",
    "    data=df[filtre].copy()\n",
    "    print(f'impute_valeurs_nutritionnelles_manquantes: \\n{data[features_to_impute].isnull().sum()}')\n",
    "\n",
    "    #other=df[~filtre]\n",
    "    if len(data)>0:\n",
    "        print(f'impute_valeurs_nutritionnelles_manquantes,   start_transform : {datetime.now().time():%H:%M:%S}')\n",
    "        imputed_features_df = pd.DataFrame(\n",
    "            imputer.transform(data[features_to_impute]),\n",
    "            columns=features_to_impute)\n",
    "        print(f'impute_valeurs_nutritionnelles_manquantes,   end_transform : {datetime.now().time():%H:%M:%S}')\n",
    "    \n",
    "        # Copié les valeurs imputés dans la dataframe\n",
    "        data=data.copy()\n",
    "        print(f'impute_valeurs_nutritionnelles_manquantes,   start_copy : {datetime.now().time():%H:%M:%S}')\n",
    "        for col in features_to_impute:\n",
    "            data[col] = imputed_features_df[col].values\n",
    "        print(f'impute_valeurs_nutritionnelles_manquantes,   end_copy : {datetime.now().time():%H:%M:%S}')\n",
    "        df=pd.concat([data,df[~filtre]],axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#check\n",
    "#test_df=data_df.sample(min(1000000,len(data_df))) # 100000 lignes = 2 h\n",
    "#test_df=data_df.sample(min(200000,len(data_df))) # 20000 lignes = 7 minutes\n",
    "#test_df=data_df.sample(min(100000,len(data_df))) # 13000 lignes= 2 minutes\n",
    "#test_df=data_df.sample(min(50000,len(data_df))) # 7000 lignes= 30 secondes\n",
    "test_df=data_df.sample(min(20000,len(data_df))) # 2600 lignes= 5 secondes\n",
    "new_df= test_df.pipe(impute_valeurs_nutritionnelles_manquantes)\n",
    "\n",
    "#print(test_df[features_nutritionnelles].isnull().sum() )\n",
    "print('----\\nNombre de valeurs manquantes imputées')\n",
    "print(new_df[features_nutritionnelles].isnull().sum()-test_df[features_nutritionnelles].isnull().sum()  )\n",
    "del test_df; del new_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "W9ztPcWbHTip",
    "outputId": "ef63416b-337d-4467-e14d-891c2c04d319"
   },
   "outputs": [],
   "source": [
    "#plot_missing_matrix(data_df[~data_df['additives_n'].isna()])\n",
    "plot_missing_matrix(data_df)\n",
    "to_png('7.4_missing_matrix_apres_imputation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "boq6OhdLgmEw"
   },
   "source": [
    "## 7.5 Pipeline pour imputer ou traiter les valeurs manquantes\n",
    "\n",
    "L'imputation des valeurs manquantes avec KNN Imputer est désactivée, \n",
    "en attendant améliorer la vitesse d'imputation et accuracy.\n",
    "\n",
    "Le pipeline d'imputation sera :\n",
    "\n",
    "- Imputer les valeurs nutritionnelles manquantes avec KNNImputer\n",
    "- On n'impute pas la catégorie nutriscore grade, car il depend du nutriscore et PNNS groupe\n",
    "- On n'impute pas les valeurs catégoriques manquantes, car l'analyse est pour explorer les relations avec ces categories\n",
    "- On supprime les données pour lequel ont n'a pas des informations sur les ingrédients, car on n'a aucune information sur les additifs\n",
    "\n",
    "Ce derniere suppression des données (sans information sur les additifs) est fait\n",
    "dans le notebook d'exploration, car on analyse les contributions à la base avant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "W-MO9Uz7gmEw",
    "outputId": "a1c24cca-7c45-4a97-a19a-dcfbeb73c2c3"
   },
   "outputs": [],
   "source": [
    "def drop_produits_sans_info_additif(df):\n",
    "    nb_sans_ingredients = df['ingredients_text'].isna().sum()\n",
    "    nb_sans_info= df['additives_n'].isna().sum()\n",
    "    print(f'drop_produits_sans_info_additif (nb = {nb_sans_info} = {nb_sans_ingredients})')\n",
    "    return df.dropna(subset=['additives_n'])\n",
    "\n",
    "data_df.pipe(drop_produits_sans_info_additif)\n",
    "print(data_df.shape)\n",
    "def plot_additifs_log_scale(df):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    additives_n=df['additives_n'].value_counts()\n",
    "    g=sns.barplot(x=additives_n.index, y=additives_n.values)\n",
    "    g.set_yscale(\"log\")\n",
    "    g.set_xlabel(\"nombre d'additifs\")\n",
    "    g.set_ylabel('nombre de produits')\n",
    "    g.set_title('Nombre de produits avec additifs (échelle logarithmique)')\n",
    "    sns.despine()\n",
    "    to_png('7.3.1_produits_avec_additifs_logscale')\n",
    "\n",
    "plot_additifs_log_scale(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXwSRA9LgmEw",
    "outputId": "df5697d5-e295-4d47-a6c0-7794f0629c02"
   },
   "outputs": [],
   "source": [
    "def pipeline_imputer_valeurs_manquantes(df):\n",
    "    print(f'pipeline_imputer_valeurs_manquantes, start_time={datetime.now().time():%H:%M:%S}')\n",
    "    return (df\n",
    "        .pipe(drop_produits_sans_info_additif)\n",
    "        #.pipe(impute_valeurs_nutritionnelles_manquantes)\n",
    "    )\n",
    "\n",
    "data_df = data_df.pipe(pipeline_imputer_valeurs_manquantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Élimination des colonnes redondantes<a name=\"colonnes-redondantes\"></a>\n",
    "La plupart de colonnes non-pertinentes ont été supprimés imédiatement après import pour réduire l'usage de mémoire RAM\n",
    "Il reste à supprimer\n",
    "- Colonnes nutritionelles en double \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B069FNeQgmEx"
   },
   "source": [
    "## 8.1 Drop colonnes_nutritionnelles en double\n",
    "\n",
    "### 8.1.1 salt_100g (duplique les données de sodium_100g) \n",
    "- pas besoin de colonne salt_100g car il est un multiple de sodium_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "E7rh3G0ggmEx",
    "outputId": "54ab5d3f-78f7-491b-c63f-5fa8f6a87b8a"
   },
   "outputs": [],
   "source": [
    "def plot_test_salt_sodium(df):\n",
    "    if len(cols_in_df(data_df,['salt_100g','sodium_100g'])) == 2:\n",
    "        sns.regplot(data=df,x='salt_100g',y='sodium_100g',scatter_kws={'s':1}, fit_reg=False)\n",
    "        to_png('8.1.3.1_test_salt_sodium_regplot')\n",
    "    \n",
    "data_df.pipe(plot_test_salt_sodium);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 energy-kcal_100g (duplique les données de energy_100g) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "w42DPrYVgmEx",
    "outputId": "5c7c7a57-7b94-4bea-a357-033bb5922654"
   },
   "outputs": [],
   "source": [
    "def plot_test_energy_kcal(df):\n",
    "    if len(cols_in_df(data_df,['energy_100g','energy-kcal_100g'])) == 2:\n",
    "        sns.regplot(data=df,x='energy_100g',y='energy-kcal_100g',scatter_kws={'s':1}, fit_reg=False)\n",
    "        #sns.scatterplot(data=df,x='salt_100g',y='sodium_100g',size=1)\n",
    "        to_png('8.1.3.2_test_energy_kcal_regplot')\n",
    "\n",
    "data_df.pipe(plot_test_energy_kcal);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uj66zorqgmEy",
    "outputId": "34514ed7-c192-4059-f61b-84aa23417765"
   },
   "outputs": [],
   "source": [
    "def drop_nutrition_cols_dupliques(df):\n",
    "    cols=['salt_100g','energy-kcal_100g']\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            print(f'drop_nutrition_cols_dupliques [{col}]')\n",
    "            df=df.drop(col,axis=1)\n",
    "    return df\n",
    "\n",
    "data_df=data_df.pipe(drop_nutrition_cols_dupliques);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8ckA78RnZID"
   },
   "source": [
    "## 8.2 Elimination des colonnes en double, composées de listes de chaines, tags etc\n",
    "- <https://world.openfoodfacts.org/data/data-fields.txt>\n",
    "- **inférence** en regardant df_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycccRWZpUxs2",
    "outputId": "3c84bcf4-f4a6-40f8-a983-adf9b3b271e0"
   },
   "outputs": [],
   "source": [
    "def find_list_colonnes(df:pd.DataFrame)-> list:\n",
    "    \"\"\"Liste des colonnes du dataframe qui contient des listes \"\"\"\n",
    "    cols= df.select_dtypes('object').columns.tolist()\n",
    "    ret=[]\n",
    "    for col in cols:\n",
    "        if col in ['product_name', 'abbreviated_product_name', 'generic_name']: continue \n",
    "        elif df[col].dropna().str.contains(',').any(): ret.append(col)\n",
    "    return ret\n",
    "\n",
    "tag_cols=find_list_colonnes(data_df)\n",
    "print(tag_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "_qo-wQXtU0js",
    "outputId": "296611f7-e819-443e-95f2-d936da00e7ba"
   },
   "outputs": [],
   "source": [
    "list_cols= ['packaging', 'brands', 'categories','labels','countries','states', 'emb', 'main_category']\n",
    "\n",
    "def decrire_liste_cols(df,racine='states'):\n",
    "   liste_cols=cols_in_df(df,[racine,f'{racine}_text',f'{racine}_tags',f'{racine}_en'])\n",
    "   liste_df= df[liste_cols].dropna(how='all')\n",
    "   print(liste_df.tail(1).T)\n",
    "   return liste_df.describe()\n",
    "\n",
    "data_df.pipe(decrire_liste_cols,'brands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXK4w3KtVJSe"
   },
   "source": [
    "\n",
    "On voit que la colonne de base est en plusieurs langues,\n",
    "qui explique pourquoi il y a plus de categories que de tags\n",
    "(qui sont en general avec prefix en:)\n",
    "\n",
    "- la colonne `categories_en` fournie la traduction anglaise des catégories\n",
    "\n",
    "Pour éliminer les données en duple ou triple :\n",
    "- garder la colonne qui termine avec `_en` s'il reste dans la base\n",
    "- sinon, garder la colonne qui termine avec `_tags`\n",
    "- sinon, garder la colonne de base\n",
    "\n",
    "On fera ça avec toutes les colonnes des tags : ['packaging', 'brands', 'categories','labels','countries','additives','states']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hhnuyaXVslE",
    "outputId": "d716a900-f9a8-4c8c-a2fd-ea63598e6da4"
   },
   "outputs": [],
   "source": [
    "def drop_tag_cols_dupliques(df, cols=['packaging', 'brands', 'categories','labels','countries','states', 'main_category']):\n",
    "    df_cols= list(df.columns)\n",
    "    cols_to_drop=[]\n",
    "    for col in cols:\n",
    "        dup_tag_cols=[]\n",
    "        if f'{col}_en' in df_cols: dup_tag_cols.append(f'{col}_en')\n",
    "        if f'{col}_tags' in df_cols: dup_tag_cols.append(f'{col}_tags')     \n",
    "        if col in df_cols: dup_tag_cols.append(col)\n",
    "        if len(dup_tag_cols)>1:\n",
    "            print (f'keep [{dup_tag_cols[0]}], drop {dup_tag_cols[1:]}')\n",
    "            cols_to_drop += dup_tag_cols[1:]\n",
    "    if len(cols_to_drop)>0:\n",
    "        return df.drop(cols_to_drop,axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df=data_df.pipe(drop_tag_cols_dupliques);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tWx0UYuaWou"
   },
   "source": [
    "## 8.3 Drop colonnes de quantity de servings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1TnmVz_bDVv",
    "outputId": "75ef8550-e3bd-48d8-b72b-ceb2692409e1"
   },
   "outputs": [],
   "source": [
    "def drop_colonnes_servings(df):\n",
    "    cols = cols_in_df(df,['quantity','serving_size','serving_quantity'])\n",
    "    if len(cols) > 0:\n",
    "        print(f'drop_colonnes_servings {cols}')\n",
    "        return df.drop(cols,axis=1)\n",
    "    else: return df\n",
    "\n",
    "data_df=data_df.pipe(drop_colonnes_servings);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlxueVjRZ-fT"
   },
   "source": [
    "## 8.4 Pipeline pour éliminer les colonnes redondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKYX14tzV74l",
    "outputId": "cff2aa14-15e5-474e-ffca-b4b894d8e83d"
   },
   "outputs": [],
   "source": [
    "def pipeline_eliminer_colonnes_redondantes(df):\n",
    "    print(f'pipeline_eliminer_colonnes_redondantes, start_time={datetime.now().time():%H:%M:%S}')\n",
    "    return (df\n",
    "            .pipe(drop_nutrition_cols_dupliques)\n",
    "            .pipe(drop_tag_cols_dupliques)\n",
    "            .pipe(drop_colonnes_servings)\n",
    "            )\n",
    "\n",
    "data_df=data_df.pipe(pipeline_eliminer_colonnes_redondantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "XpjwLqtsgmEz"
   },
   "source": [
    "# 9. Enregistrement du dataframe nettoyé<a name=\"enregistrement\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCyc54EVPRTG"
   },
   "outputs": [],
   "source": [
    "colonnes_a_importer=data_df.columns.to_list()\n",
    "data_df = None\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uh75ndFDgmEz",
    "outputId": "d8d1d1b0-1048-4a02-cdec-ba55f19b5f1a"
   },
   "outputs": [],
   "source": [
    "data_df = (read_raw_data(colonnes=colonnes_a_importer)\n",
    "               .pipe(pipeline_corriger_types)\n",
    "               .pipe(pipeline_eliminer_colonnes_inutiles)\n",
    "               .pipe(pipeline_eliminer_lignes_dupliquees)\n",
    "               .pipe(pipeline_traiter_valeurs_manquantes)\n",
    "               .pipe(pipeline_traiter_valeurs_aberrantes)\n",
    "               #.pipe(pipeline_imputer_valeurs_manquantes)\n",
    "               .pipe(pipeline_eliminer_colonnes_redondantes)\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMN3CwXrgmEz",
    "outputId": "b428fe68-b58f-45e3-cbcb-e541ac122698"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(data_df_shape)\n",
    "print(data_df.shape)\n",
    "\n",
    "print(list(data_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6JlJNRwwIa0",
    "outputId": "a770c9ac-3a43-4201-a1e9-6f8fa9c53864"
   },
   "outputs": [],
   "source": [
    "print(data_df['nova_group'].dtype)\n",
    "print(data_df['nova_group'].count())\n",
    "data_df['nova_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_5zgnGBOgmEz"
   },
   "source": [
    "## 9.1. Enregistre les données et un dictionnaire de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WHmOgF6QgmEz",
    "outputId": "801220b7-ff18-40c9-eb4d-6c7ca7019126"
   },
   "outputs": [],
   "source": [
    "clean_data_dict=data_df.pipe(decrire_dataframe, calc_max_len=True)\n",
    "clean_data_dict.to_csv(os_path_join(OUT_FOLDER,CLEAN_DATA_DICT), encoding='UTF-8', sep='\\t', index=False)\n",
    "clean_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYRCt_zbgmEz"
   },
   "outputs": [],
   "source": [
    "data_df.to_csv(os_path_join(OUT_FOLDER,CLEAN_DATA_FILENAME), \n",
    "                encoding='UTF-8', sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmkuPFaUeTCU"
   },
   "outputs": [],
   "source": [
    "sample_size=min(100000,len(data_df))\n",
    "data_df.sample(sample_size).to_csv(os_path_join(OUT_FOLDER,CLEAN_DATA_SAMPLE),\n",
    "                              encoding='UTF-8', sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Données nettoyés - Taux de remplissage\n",
    "Il y a deux parties de l'analyse exploratoire: \n",
    "- analyse des contributeurs (est-ce qu'on peux intégrer les données d'additifs de tous les pays et contributeurs?)\n",
    "- analyse des additifs (seulement avec données ou l'information des additifs est présent)\n",
    "\n",
    "### 9.2.1 Données pour l'analyse des contributeurs - taux de remplissage \n",
    "La premier partie d'analyse exploratoire analyse les données manquantes : l'effet de pays et contributeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "lsrIUGJjgmE0",
    "outputId": "5cc039b3-8625-4255-cb69-c353f0cff9a6"
   },
   "outputs": [],
   "source": [
    "(data_df\n",
    " .pipe(sort_by_priority)\n",
    " .pipe(msno.matrix))\n",
    "plt.title(label=\"Données nettoyés - Taux de remplissage matrix\", size=24)\n",
    "to_png('10_cleaned_data_taux_de_remplissage_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "Pxd4MKTBgmE0",
    "outputId": "8fb6490b-8ff0-47b7-a058-ec326ec19cc1"
   },
   "outputs": [],
   "source": [
    "data_df.pipe(plot_colonne_remplissage,titre='Données nettoyés : taux de remplissage',\n",
    "figsize=(12, 6))\n",
    "to_png('10_cleaned_data_taux_de_remplissage_barplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.1 Données pour l'analyse des additifs - taux de remplissage\n",
    "\n",
    "Pour la reste de l'analyse exploratoire,  les produits sans information sur les additifs sont supprimés (après des tests statistiques)\n",
    "\n",
    "Ci-dessous, le taux de remplissage des données sans information sur les additifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "g8RIoA7oYadO",
    "outputId": "5d08f17b-9ebc-4b01-b580-25da3fcc7bea"
   },
   "outputs": [],
   "source": [
    "(data_df\n",
    " .pipe(drop_produits_sans_info_additif)\n",
    " .pipe(sort_by_priority)\n",
    " .pipe(msno.matrix))\n",
    "plt.title(label=\"Données nettoyés (avec info additifs) - Taux de remplissage matrix\", size=24)\n",
    "to_png('10_cleaned_data_additifs_taux_de_remplissage_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "vCVYKEtGUDnA",
    "outputId": "7472a9e8-7743-46da-edd7-d294a40723a3"
   },
   "outputs": [],
   "source": [
    "(data_df\n",
    "   .pipe(drop_produits_sans_info_additif)\n",
    "   .pipe(plot_bar_remplissage,\n",
    "         titre='Données nettoyés avec info additifs : taux de remplissage',\n",
    "         figsize=(10, 10))\n",
    ")\n",
    "to_png('10_cleaned_data_additifs_taux_de_remplissage_barplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "lffbw4smgmE0"
   },
   "source": [
    "# 10. Conversion des données supplémentaires des additives (du site Open Food Facts)\n",
    "Nombre de produits qui contient des additives :\n",
    "- https://world.openfoodfacts.org/additives\n",
    "- https://world.openfoodfacts.org/additives.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "JrMpxzl2gmE0"
   },
   "source": [
    "## 10.1 Télécharge le fichier json du site `openfoodfacts.org`\n",
    "\n",
    "Les détails des propriétés des additives sont disponibles sur :\n",
    "-  https://world.openfoodfacts.org/data/taxonomies/additives.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMTqG591gmE0",
    "outputId": "d3c2208f-a352-4919-8a53-5e446339211c"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(file):\n",
    "    with open(file, encoding='UTF-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(obj,file):\n",
    "    with open(file, 'w', encoding='UTF-8') as outfile:\n",
    "        json.dump(obj, outfile)\n",
    "\n",
    "def load_json_file_or_url(file,url):\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            return load_json(file)\n",
    "        except IOError:\n",
    "            print(f'error loading json file : {file}')\n",
    "    f=requests.get(url).json()\n",
    "    save_json(f,file)\n",
    "    return f\n",
    "\n",
    "def get_file_or_url(file,url):\n",
    "    if os.path.exists(file):\n",
    "            return file\n",
    "    else:\n",
    "        response=requests.get(url)\n",
    "        with open(file, \"w\",encoding='UTF-8') as f:\n",
    "            f.write(response.text)\n",
    "        return file\n",
    "\n",
    "off_additives_detail_json_url='https://world.openfoodfacts.org/data/taxonomies/additives.json'\n",
    "local_additives_detail_json=os_path_join(OUT_FOLDER,'additives_detail.json')\n",
    "\n",
    "additives_detail_json = load_json_file_or_url(local_additives_detail_json,off_additives_detail_json_url)\n",
    "print(list(additives_detail_json.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "FdFsvmBdgmE0"
   },
   "source": [
    "## 10.2 Convertir additives json vers dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "c5ZSROGxgmE0",
    "outputId": "f6cc7ece-5e0f-4bc2-b9fe-6ef67357f854"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(additives_detail_json, orient='index').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "Ydv_cpoYgmE0",
    "outputId": "4db63ecb-3704-485d-a1c0-b8d92bde9d24"
   },
   "outputs": [],
   "source": [
    "def normalize_additive_json(data):\n",
    "    \"\"\"Extraire les champs en anglais du fichier additives.json\"\"\"\n",
    "    data, index = list(data.values()), list(data.keys())\n",
    "    df = pd.json_normalize(data)\n",
    "    df.index = index\n",
    "    df = df.rename_axis('id')\n",
    "    filtre = df.columns.str.endswith('.en')  #seulement les colonnes en anglais\n",
    "    df = df[df.columns[filtre]]\n",
    "    # supprime '.en'\n",
    "    df.columns = [str(col)[:-3] for col in df.columns]\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "additives_detail_df = normalize_additive_json(additives_detail_json)\n",
    "print(additives_detail_df.shape)\n",
    "additives_detail_df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "P_gvTmLzgmE1"
   },
   "source": [
    "## 10.3 Enregistre le fichier 'additive_details.csv' pour l'analyse exploratoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gCmhbT3gmE1"
   },
   "outputs": [],
   "source": [
    "additives_detail_df.to_csv(os_path_join(OUT_FOLDER, ADDITIVES_DETAIL),\n",
    "                           encoding='UTF-8',sep='\\t',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "P3_nettoyage_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "a0c4969017d99d386ec3e08191b6f994618d2885196bfce758f351869385c277"
  },
  "kernelspec": {
   "display_name": "PyCharm (OC__P2_ADSE)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
